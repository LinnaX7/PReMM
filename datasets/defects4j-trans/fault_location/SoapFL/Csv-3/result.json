{
    "buggy_classes": [
        "org.apache.commons.csv.Lexer"
    ],
    "buggy_methods": [
        {
            "method_name": "org.apache.commons.csv.CSVLexer::nextToken(Token)",
            "method_code": "```java\n    @Override\n    Token nextToken(final Token token) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.getLastChar();\n\n        // read the next char and set eol\n        int c = in.read();\n        /*\n         * Note: The following call will swallow LF if c == CR. But we don't need to know if the last char was CR or LF\n         * - they are equivalent here.\n         */\n        boolean eol = readEndOfLine(c);\n\n        // empty line detection: eol AND (last char was EOL or beginning)\n        if (ignoreEmptyLines) {\n            while (eol && isStartOfLine(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = readEndOfLine(c);\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    token.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return token;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            token.type = EOF;\n            // don't set tkn.isReady here because no content\n            return token;\n        }\n\n        if (isStartOfLine(lastChar) && isCommentStart(c)) {\n            final String comment = in.readLine().trim();\n            token.content.append(comment);\n            token.type = COMMENT;\n            return token;\n        }\n\n        // important: make sure a new char gets consumed in each iteration\n        while (token.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (ignoreSurroundingSpaces) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = readEndOfLine(c);\n                }\n            }\n\n            // ok, start of token reached: encapsulated, or token\n            if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                token.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                // noop: tkn.content.append(\"\");\n                token.type = EORECORD;\n            } else if (isQuoteChar(c)) {\n                // consume encapsulated token\n                parseEncapsulatedToken(token);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                // noop: tkn.content.append(\"\");\n                token.type = EOF;\n                token.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                parseSimpleToken(token, c);\n            }\n        }\n        return token;\n    }\n\n```",
            "method_doc": " Returns the next token. <p/> A token corresponds to a term, a record change or an end-of-file indicator.  @param token an existing Token object to reuse. The caller is responsible to initialize the Token. @return the next token found @throws java.io.IOException on stream access error ",
            "class_name": "org.apache.commons.csv.CSVLexer",
            "class_doc": "   @version $Id$ ",
            "test_failure_causes": "Based on my analysis of the failed tests, I've identified the common patterns and possible defect in the production code:\n\n## Common Patterns Identified:\n\n1. **Both tests involve escaped sequences** - `\\N` in the MySQL null test and `\\a` in the escaped character test\n2. **Identical failure pattern** - In both cases, the backslash (`\\`) is being removed from the output\n3. **Same assertion failure** - Expected content contains `\\\\` (escaped backslash) but actual output shows the character after backslash only\n4. **Identical test setup** - Both use the same CSV format configuration with backslash as escape character\n\n## Root Cause Analysis:\n\nThe tests expect the lexer to treat the backslash as a literal character and preserve it in the output. However, the actual output shows the backslash is being stripped, leaving only the character that follows it (`N` or `a`).\n\n## Recommended Possible Defect in Production Code:\n\nThe defect likely exists in the `CSVLexer.nextToken()` method or related parsing logic where **escape character processing is incorrectly handling the case when a backslash is followed by another character**. \n\nSpecifically, the production code appears to be:\n- **Incorrectly interpreting the backslash as an escape character** even when it should be treated as a literal\n- **Removing the backslash** and only preserving the following character\n- **Failing to properly handle escaped backslashes** (`\\\\` should result in a single literal backslash in output)\n\nThe bug is likely in the escape sequence parsing logic where the code doesn't properly distinguish between when a backslash should escape the following character versus when it should be treated as a literal character itself. This could be in a state machine or character-by-character parsing loop within the lexer implementation.",
            "test_suite": "org.apache.commons.csv.CSVLexerTest",
            "score": 9,
            "reason": "#9# This method is very likely to be the best location that needs to be fixed because it contains the main token parsing logic and delegates to parseSimpleToken method which likely handles escape character processing. The test failures show that backslashes are being incorrectly stripped from the output, indicating a problem in the lexer's character processing logic. Since this method orchestrates the entire token parsing workflow and calls parseSimpleToken for non-encapsulated tokens, any issues with escape character handling would originate from or be controlled by this method's parsing flow."
        },
        {
            "method_name": "org.apache.commons.csv.CSVLexer::parseSimpleToken(Token,int)",
            "method_code": "```java\n    private Token parseSimpleToken(final Token tkn, int c) throws IOException {\n        // Faster to use while(true)+break than while(tkn.type == INVALID)\n        while (true) {\n            if (readEndOfLine(c)) {\n                tkn.type = EORECORD;\n                break;\n            } else if (isEndOfFile(c)) {\n                tkn.type = EOF;\n                tkn.isReady = true; // There is data at EOF\n                break;\n            } else if (isDelimiter(c)) {\n                tkn.type = TOKEN;\n                break;\n            } else if (isEscape(c)) {\n                final int unescaped = readEscape();\n                if (unescaped == Constants.END_OF_STREAM) { // unexpected char after escape\n                    tkn.content.append((char) c).append((char) in.getLastChar());\n                } else {\n                    tkn.content.append((char) unescaped);\n                }\n                c = in.read(); // continue\n            } else {\n                tkn.content.append((char) c);\n                c = in.read(); // continue\n            }\n        }\n\n        if (ignoreSurroundingSpaces) {\n            trimTrailingSpaces(tkn.content);\n        }\n\n        return tkn;\n    }\n\n```",
            "method_doc": " Parses a simple token. <p/> Simple token are tokens which are not surrounded by encapsulators. A simple token might contain escaped delimiters (as \\, or \\;). The token is finished when one of the following conditions become true: <ul> <li>end of line has been reached (EORECORD)</li> <li>end of stream has been reached (EOF)</li> <li>an unescaped delimiter has been reached (TOKEN)</li> </ul>  @param tkn the current token @param c the current character @return the filled token @throws IOException on stream access error ",
            "class_name": "org.apache.commons.csv.CSVLexer",
            "class_doc": "   @version $Id$ ",
            "test_failure_causes": "Based on my analysis of the failed tests, I've identified the common patterns and possible defect in the production code:\n\n## Common Patterns Identified:\n\n1. **Both tests involve escaped sequences** - `\\N` in the MySQL null test and `\\a` in the escaped character test\n2. **Identical failure pattern** - In both cases, the backslash (`\\`) is being removed from the output\n3. **Same assertion failure** - Expected content contains `\\\\` (escaped backslash) but actual output shows the character after backslash only\n4. **Identical test setup** - Both use the same CSV format configuration with backslash as escape character\n\n## Root Cause Analysis:\n\nThe tests expect the lexer to treat the backslash as a literal character and preserve it in the output. However, the actual output shows the backslash is being stripped, leaving only the character that follows it (`N` or `a`).\n\n## Recommended Possible Defect in Production Code:\n\nThe defect likely exists in the `CSVLexer.nextToken()` method or related parsing logic where **escape character processing is incorrectly handling the case when a backslash is followed by another character**. \n\nSpecifically, the production code appears to be:\n- **Incorrectly interpreting the backslash as an escape character** even when it should be treated as a literal\n- **Removing the backslash** and only preserving the following character\n- **Failing to properly handle escaped backslashes** (`\\\\` should result in a single literal backslash in output)\n\nThe bug is likely in the escape sequence parsing logic where the code doesn't properly distinguish between when a backslash should escape the following character versus when it should be treated as a literal character itself. This could be in a state machine or character-by-character parsing loop within the lexer implementation.",
            "test_suite": "org.apache.commons.csv.CSVLexerTest",
            "score": 9,
            "reason": "#9# This method is highly suspicious because it contains the escape character handling logic that is causing the test failures. The issue is in the `isEscape(c)` branch where when an escape character is detected, the code calls `readEscape()` and appends only the unescaped character to the token content, completely removing the backslash. This explains why both tests show the backslash being stripped from the output - the method is treating the backslash as an escape character rather than preserving it as a literal character when it should be part of the token content."
        },
        {
            "method_name": "org.apache.commons.csv.Lexer::readEscape()",
            "method_code": "```java\n    int readEscape() throws IOException {\n        if (!(!(false))) {\n            System.out.println(\"log\");\n        }\n        // the escape char has just been read (normally a backslash)\n        final int TransVarC1 = in.read();\n        switch (TransVarC1) {\n        case 'r':\n            return CR;\n        case 'n':\n            return LF;\n        case 't':\n            return TAB;\n        case 'b':\n            return BACKSPACE;\n        case 'f':\n            return FF;\n        case CR:\n        case LF:\n        case FF: // TODO is this correct?\n        case TAB: // TODO is this correct? Do tabs need to be escaped?\n        case BACKSPACE: // TODO is this correct?\n            return TransVarC1;\n        case END_OF_STREAM:\n            throw new IOException(\"EOF whilst processing escape sequence\");\n        default:\n            // Now check for meta-characters\n                return TransVarC1;\n            // indicate unexpected char - available from in.getLastChar()\n        }\n    }\n\n```",
            "method_doc": " Handle an escape sequence. The current character must be the escape character. On return, the next character is available by calling {@link ExtendedBufferedReader#getLastChar()} on the input stream.  @return the unescaped character (as an int) or {@link END_OF_STREAM} if char following the escape is invalid.  @throws IOException if there is a problem reading the stream or the end of stream is detected:  the escape character is not allowed at end of strem ",
            "class_name": "org.apache.commons.csv.Lexer",
            "class_doc": " Abstract lexer class; contains common utility routines shared by lexers  @version $Id$ ",
            "test_failure_causes": "Looking at the failed test `testBackslashEscaping`, I can identify the key issue by analyzing the test behavior and stack trace:\n\n## Analysis of the Failure\n\n**Key Evidence from Stack Trace:**\n```\nexpected:<   \"quoted \"\" [/]\" / string\"   > \nbut was:<   \"quoted \"\" []\" / string\"   >\n```\n\nThe discrepancy occurs at entry 8, specifically in the second field where:\n- Expected: `\"quoted \"\" /\" / string\"` (contains `/`)\n- Actual: `\"quoted \"\" \" / string\"` (missing `/`)\n\n**Pattern Analysis:**\nThe test uses forward slash (`/`) as the escape character and processes complex escaping scenarios. The failure specifically occurs when handling escaped characters within quoted fields that contain multiple layers of escaping and quoting.\n\n## Recommended Defect in Production Code\n\nThe likely defect is in the **CSV parsing logic for handling escape characters within quoted fields**. Specifically, the production code appears to be incorrectly processing escape sequences when they appear in combination with quote characters inside quoted fields.\n\n**Probable Location:** \nThe bug likely exists in the `Lexer` or tokenization logic of `CSVParser` where escape character processing occurs, particularly in the method that handles quoted field parsing.\n\n**Root Cause Hypothesis:**\nThe parser is likely:\n1. Correctly identifying the start of a quoted field\n2. But incorrectly processing escape sequences within quoted fields, possibly by:\n   - Removing escape characters when they should be preserved\n   - Failing to properly handle escape characters that precede other special characters\n   - Incorrectly terminating quoted fields when encountering escaped sequences\n\n**Specific Focus Area:**\nThe production code methods responsible for:\n- `CSVLexer.parseEncapsulatedToken()` or similar quoted field parsing logic\n- Escape character processing within the context of quoted fields\n- The state machine that tracks escaping behavior during field parsing\n\nThe defect manifests as the parser incorrectly removing or misinterpreting the forward slash escape character in complex quoted/escaped scenarios, particularly when multiple special characters are involved.",
            "test_suite": "org.apache.commons.csv.CSVParserTest",
            "score": 8,
            "reason": "#8# The readEscape() method is very likely to be the best location that needs to be fixed because it handles escape character processing, and the test failure specifically involves incorrect handling of forward slash escape sequences within quoted fields. The method's switch statement doesn't properly handle the forward slash escape character case, and the default case simply returns the escaped character without any special processing, which could cause the parser to incorrectly interpret escaped sequences in complex scenarios like the one shown in the test failure."
        },
        {
            "method_name": "org.apache.commons.csv.Lexer::isEscape(int)",
            "method_code": "```java\n    boolean isEscape(final int c) {\n        return c == escape;\n    }\n\n```",
            "method_doc": "Checks if character matches configured escape character.",
            "class_name": "org.apache.commons.csv.Lexer",
            "class_doc": " Abstract lexer class; contains common utility routines shared by lexers  @version $Id$ ",
            "test_failure_causes": "Looking at the failed test `testBackslashEscaping`, I can identify the key issue by analyzing the test behavior and stack trace:\n\n## Analysis of the Failure\n\n**Key Evidence from Stack Trace:**\n```\nexpected:<   \"quoted \"\" [/]\" / string\"   > \nbut was:<   \"quoted \"\" []\" / string\"   >\n```\n\nThe discrepancy occurs at entry 8, specifically in the second field where:\n- Expected: `\"quoted \"\" /\" / string\"` (contains `/`)\n- Actual: `\"quoted \"\" \" / string\"` (missing `/`)\n\n**Pattern Analysis:**\nThe test uses forward slash (`/`) as the escape character and processes complex escaping scenarios. The failure specifically occurs when handling escaped characters within quoted fields that contain multiple layers of escaping and quoting.\n\n## Recommended Defect in Production Code\n\nThe likely defect is in the **CSV parsing logic for handling escape characters within quoted fields**. Specifically, the production code appears to be incorrectly processing escape sequences when they appear in combination with quote characters inside quoted fields.\n\n**Probable Location:** \nThe bug likely exists in the `Lexer` or tokenization logic of `CSVParser` where escape character processing occurs, particularly in the method that handles quoted field parsing.\n\n**Root Cause Hypothesis:**\nThe parser is likely:\n1. Correctly identifying the start of a quoted field\n2. But incorrectly processing escape sequences within quoted fields, possibly by:\n   - Removing escape characters when they should be preserved\n   - Failing to properly handle escape characters that precede other special characters\n   - Incorrectly terminating quoted fields when encountering escaped sequences\n\n**Specific Focus Area:**\nThe production code methods responsible for:\n- `CSVLexer.parseEncapsulatedToken()` or similar quoted field parsing logic\n- Escape character processing within the context of quoted fields\n- The state machine that tracks escaping behavior during field parsing\n\nThe defect manifests as the parser incorrectly removing or misinterpreting the forward slash escape character in complex quoted/escaped scenarios, particularly when multiple special characters are involved.",
            "test_suite": "org.apache.commons.csv.CSVParserTest",
            "score": 3,
            "reason": "#3# The isEscape method is too simple to be the root cause - it only checks if a character matches the configured escape character. The actual bug appears to be in how escape sequences are processed within quoted fields, particularly when handling complex escaping scenarios with multiple special characters. The failure shows the parser is incorrectly removing escape characters in quoted fields, which suggests issues in the parsing logic that uses this method rather than the method itself."
        },
        {
            "method_name": "org.apache.commons.csv.Lexer::isQuoteChar(int)",
            "method_code": "```java\n    boolean isQuoteChar(final int c) {\n        return c == quoteChar;\n    }\n\n```",
            "method_doc": "Checks if character matches configured quote character.",
            "class_name": "org.apache.commons.csv.Lexer",
            "class_doc": " Abstract lexer class; contains common utility routines shared by lexers  @version $Id$ ",
            "test_failure_causes": "Looking at the failed test `testBackslashEscaping`, I can identify the key issue by analyzing the test behavior and stack trace:\n\n## Analysis of the Failure\n\n**Key Evidence from Stack Trace:**\n```\nexpected:<   \"quoted \"\" [/]\" / string\"   > \nbut was:<   \"quoted \"\" []\" / string\"   >\n```\n\nThe discrepancy occurs at entry 8, specifically in the second field where:\n- Expected: `\"quoted \"\" /\" / string\"` (contains `/`)\n- Actual: `\"quoted \"\" \" / string\"` (missing `/`)\n\n**Pattern Analysis:**\nThe test uses forward slash (`/`) as the escape character and processes complex escaping scenarios. The failure specifically occurs when handling escaped characters within quoted fields that contain multiple layers of escaping and quoting.\n\n## Recommended Defect in Production Code\n\nThe likely defect is in the **CSV parsing logic for handling escape characters within quoted fields**. Specifically, the production code appears to be incorrectly processing escape sequences when they appear in combination with quote characters inside quoted fields.\n\n**Probable Location:** \nThe bug likely exists in the `Lexer` or tokenization logic of `CSVParser` where escape character processing occurs, particularly in the method that handles quoted field parsing.\n\n**Root Cause Hypothesis:**\nThe parser is likely:\n1. Correctly identifying the start of a quoted field\n2. But incorrectly processing escape sequences within quoted fields, possibly by:\n   - Removing escape characters when they should be preserved\n   - Failing to properly handle escape characters that precede other special characters\n   - Incorrectly terminating quoted fields when encountering escaped sequences\n\n**Specific Focus Area:**\nThe production code methods responsible for:\n- `CSVLexer.parseEncapsulatedToken()` or similar quoted field parsing logic\n- Escape character processing within the context of quoted fields\n- The state machine that tracks escaping behavior during field parsing\n\nThe defect manifests as the parser incorrectly removing or misinterpreting the forward slash escape character in complex quoted/escaped scenarios, particularly when multiple special characters are involved.",
            "test_suite": "org.apache.commons.csv.CSVParserTest",
            "score": 3,
            "reason": "#3# The isQuoteChar method simply compares a character with the configured quote character, which is a straightforward equality check. The test failure involves complex escaping scenarios where forward slash is used as escape character within quoted fields containing multiple special characters. The issue appears to be in escape sequence processing logic rather than basic quote character identification. The method is too simple to be the root cause of the complex escaping failure observed in the test."
        },
        {
            "method_name": "org.apache.commons.csv.Lexer::Lexer(CSVFormat,ExtendedBufferedReader)",
            "method_code": "```java\n    Lexer(final CSVFormat format, final ExtendedBufferedReader in) {\n        this.format = format;\n        this.in = in;\n        this.delimiter = format.getDelimiter();\n        this.escape = mapNullToDisabled(format.getEscape());\n        this.quoteChar = mapNullToDisabled(format.getQuoteChar());\n        this.commmentStart = mapNullToDisabled(format.getCommentStart());\n        this.ignoreSurroundingSpaces = format.getIgnoreSurroundingSpaces();\n        this.ignoreEmptyLines = format.getIgnoreEmptyLines();\n    }\n\n```",
            "method_doc": "Constructor initializes lexer configuration, calling mapNullToDisabled method three times to process escape, quoteChar, and commmentStart parameters.",
            "class_name": "org.apache.commons.csv.Lexer",
            "class_doc": " Abstract lexer class; contains common utility routines shared by lexers  @version $Id$ ",
            "test_failure_causes": "Looking at the failed test `testBackslashEscaping`, I can identify the key issue by analyzing the test behavior and stack trace:\n\n## Analysis of the Failure\n\n**Key Evidence from Stack Trace:**\n```\nexpected:<   \"quoted \"\" [/]\" / string\"   > \nbut was:<   \"quoted \"\" []\" / string\"   >\n```\n\nThe discrepancy occurs at entry 8, specifically in the second field where:\n- Expected: `\"quoted \"\" /\" / string\"` (contains `/`)\n- Actual: `\"quoted \"\" \" / string\"` (missing `/`)\n\n**Pattern Analysis:**\nThe test uses forward slash (`/`) as the escape character and processes complex escaping scenarios. The failure specifically occurs when handling escaped characters within quoted fields that contain multiple layers of escaping and quoting.\n\n## Recommended Defect in Production Code\n\nThe likely defect is in the **CSV parsing logic for handling escape characters within quoted fields**. Specifically, the production code appears to be incorrectly processing escape sequences when they appear in combination with quote characters inside quoted fields.\n\n**Probable Location:** \nThe bug likely exists in the `Lexer` or tokenization logic of `CSVParser` where escape character processing occurs, particularly in the method that handles quoted field parsing.\n\n**Root Cause Hypothesis:**\nThe parser is likely:\n1. Correctly identifying the start of a quoted field\n2. But incorrectly processing escape sequences within quoted fields, possibly by:\n   - Removing escape characters when they should be preserved\n   - Failing to properly handle escape characters that precede other special characters\n   - Incorrectly terminating quoted fields when encountering escaped sequences\n\n**Specific Focus Area:**\nThe production code methods responsible for:\n- `CSVLexer.parseEncapsulatedToken()` or similar quoted field parsing logic\n- Escape character processing within the context of quoted fields\n- The state machine that tracks escaping behavior during field parsing\n\nThe defect manifests as the parser incorrectly removing or misinterpreting the forward slash escape character in complex quoted/escaped scenarios, particularly when multiple special characters are involved.",
            "test_suite": "org.apache.commons.csv.CSVParserTest",
            "score": 2,
            "reason": "#2# This method is just a constructor that initializes configuration parameters and doesn't contain any parsing logic. The actual bug is likely in the parsing logic that processes escape sequences within quoted fields, not in this initialization code."
        }
    ],
    "buggy_codes": {
        "org.apache.commons.csv.CSVLexer::nextToken(Token)": {
            "method_name": "org.apache.commons.csv.CSVLexer::nextToken(Token)",
            "method_code": "```java\n    @Override\n    Token nextToken(final Token token) throws IOException {\n\n        // get the last read char (required for empty line detection)\n        int lastChar = in.getLastChar();\n\n        // read the next char and set eol\n        int c = in.read();\n        /*\n         * Note: The following call will swallow LF if c == CR. But we don't need to know if the last char was CR or LF\n         * - they are equivalent here.\n         */\n        boolean eol = readEndOfLine(c);\n\n        // empty line detection: eol AND (last char was EOL or beginning)\n        if (ignoreEmptyLines) {\n            while (eol && isStartOfLine(lastChar)) {\n                // go on char ahead ...\n                lastChar = c;\n                c = in.read();\n                eol = readEndOfLine(c);\n                // reached end of file without any content (empty line at the end)\n                if (isEndOfFile(c)) {\n                    token.type = EOF;\n                    // don't set tkn.isReady here because no content\n                    return token;\n                }\n            }\n        }\n\n        // did we reach eof during the last iteration already ? EOF\n        if (isEndOfFile(lastChar) || (!isDelimiter(lastChar) && isEndOfFile(c))) {\n            token.type = EOF;\n            // don't set tkn.isReady here because no content\n            return token;\n        }\n\n        if (isStartOfLine(lastChar) && isCommentStart(c)) {\n            final String comment = in.readLine().trim();\n            token.content.append(comment);\n            token.type = COMMENT;\n            return token;\n        }\n\n        // important: make sure a new char gets consumed in each iteration\n        while (token.type == INVALID) {\n            // ignore whitespaces at beginning of a token\n            if (ignoreSurroundingSpaces) {\n                while (isWhitespace(c) && !eol) {\n                    c = in.read();\n                    eol = readEndOfLine(c);\n                }\n            }\n\n            // ok, start of token reached: encapsulated, or token\n            if (isDelimiter(c)) {\n                // empty token return TOKEN(\"\")\n                token.type = TOKEN;\n            } else if (eol) {\n                // empty token return EORECORD(\"\")\n                // noop: tkn.content.append(\"\");\n                token.type = EORECORD;\n            } else if (isQuoteChar(c)) {\n                // consume encapsulated token\n                parseEncapsulatedToken(token);\n            } else if (isEndOfFile(c)) {\n                // end of file return EOF()\n                // noop: tkn.content.append(\"\");\n                token.type = EOF;\n                token.isReady = true; // there is data at EOF\n            } else {\n                // next token must be a simple token\n                // add removed blanks when not ignoring whitespace chars...\n                parseSimpleToken(token, c);\n            }\n        }\n        return token;\n    }\n\n```",
            "method_doc": " Returns the next token. <p/> A token corresponds to a term, a record change or an end-of-file indicator.  @param token an existing Token object to reuse. The caller is responsible to initialize the Token. @return the next token found @throws java.io.IOException on stream access error "
        },
        "org.apache.commons.csv.CSVLexer::parseSimpleToken(Token,int)": {
            "method_name": "org.apache.commons.csv.CSVLexer::parseSimpleToken(Token,int)",
            "method_code": "```java\n    private Token parseSimpleToken(final Token tkn, int c) throws IOException {\n        // Faster to use while(true)+break than while(tkn.type == INVALID)\n        while (true) {\n            if (readEndOfLine(c)) {\n                tkn.type = EORECORD;\n                break;\n            } else if (isEndOfFile(c)) {\n                tkn.type = EOF;\n                tkn.isReady = true; // There is data at EOF\n                break;\n            } else if (isDelimiter(c)) {\n                tkn.type = TOKEN;\n                break;\n            } else if (isEscape(c)) {\n                final int unescaped = readEscape();\n                if (unescaped == Constants.END_OF_STREAM) { // unexpected char after escape\n                    tkn.content.append((char) c).append((char) in.getLastChar());\n                } else {\n                    tkn.content.append((char) unescaped);\n                }\n                c = in.read(); // continue\n            } else {\n                tkn.content.append((char) c);\n                c = in.read(); // continue\n            }\n        }\n\n        if (ignoreSurroundingSpaces) {\n            trimTrailingSpaces(tkn.content);\n        }\n\n        return tkn;\n    }\n\n```",
            "method_doc": " Parses a simple token. <p/> Simple token are tokens which are not surrounded by encapsulators. A simple token might contain escaped delimiters (as \\, or \\;). The token is finished when one of the following conditions become true: <ul> <li>end of line has been reached (EORECORD)</li> <li>end of stream has been reached (EOF)</li> <li>an unescaped delimiter has been reached (TOKEN)</li> </ul>  @param tkn the current token @param c the current character @return the filled token @throws IOException on stream access error "
        },
        "org.apache.commons.csv.Lexer::readEscape()": {
            "method_name": "org.apache.commons.csv.Lexer::readEscape()",
            "method_code": "```java\n    int readEscape() throws IOException {\n        if (!(!(false))) {\n            System.out.println(\"log\");\n        }\n        // the escape char has just been read (normally a backslash)\n        final int TransVarC1 = in.read();\n        switch (TransVarC1) {\n        case 'r':\n            return CR;\n        case 'n':\n            return LF;\n        case 't':\n            return TAB;\n        case 'b':\n            return BACKSPACE;\n        case 'f':\n            return FF;\n        case CR:\n        case LF:\n        case FF: // TODO is this correct?\n        case TAB: // TODO is this correct? Do tabs need to be escaped?\n        case BACKSPACE: // TODO is this correct?\n            return TransVarC1;\n        case END_OF_STREAM:\n            throw new IOException(\"EOF whilst processing escape sequence\");\n        default:\n            // Now check for meta-characters\n                return TransVarC1;\n            // indicate unexpected char - available from in.getLastChar()\n        }\n    }\n\n```",
            "method_doc": " Handle an escape sequence. The current character must be the escape character. On return, the next character is available by calling {@link ExtendedBufferedReader#getLastChar()} on the input stream.  @return the unescaped character (as an int) or {@link END_OF_STREAM} if char following the escape is invalid.  @throws IOException if there is a problem reading the stream or the end of stream is detected:  the escape character is not allowed at end of strem "
        },
        "org.apache.commons.csv.Lexer::Lexer(CSVFormat,ExtendedBufferedReader)": {
            "method_name": "org.apache.commons.csv.Lexer::Lexer(CSVFormat,ExtendedBufferedReader)",
            "method_code": "```java\n    Lexer(final CSVFormat format, final ExtendedBufferedReader in) {\n        this.format = format;\n        this.in = in;\n        this.delimiter = format.getDelimiter();\n        this.escape = mapNullToDisabled(format.getEscape());\n        this.quoteChar = mapNullToDisabled(format.getQuoteChar());\n        this.commmentStart = mapNullToDisabled(format.getCommentStart());\n        this.ignoreSurroundingSpaces = format.getIgnoreSurroundingSpaces();\n        this.ignoreEmptyLines = format.getIgnoreEmptyLines();\n    }\n\n```",
            "method_doc": "Constructor initializes lexer configuration, calling mapNullToDisabled method three times to process escape, quoteChar, and commmentStart parameters."
        },
        "org.apache.commons.csv.Lexer::isEscape(int)": {
            "method_name": "org.apache.commons.csv.Lexer::isEscape(int)",
            "method_code": "```java\n    boolean isEscape(final int c) {\n        return c == escape;\n    }\n\n```",
            "method_doc": "Checks if character matches configured escape character."
        },
        "org.apache.commons.csv.Lexer::isQuoteChar(int)": {
            "method_name": "org.apache.commons.csv.Lexer::isQuoteChar(int)",
            "method_code": "```java\n    boolean isQuoteChar(final int c) {\n        return c == quoteChar;\n    }\n\n```",
            "method_doc": "Checks if character matches configured quote character."
        }
    }
}