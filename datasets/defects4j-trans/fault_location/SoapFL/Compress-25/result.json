{
    "buggy_classes": [
        "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream"
    ],
    "buggy_methods": [
        {
            "method_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::readStored(byte[],int,int)",
            "method_code": "```java\n    private int readStored(byte[] buffer, int offset, int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(buf.limit());\n            current.bytesReadFromStream += buf.limit();\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n```",
            "method_doc": " Implementation of read for STORED entries. ",
            "class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream",
            "class_doc": " Implements an input stream that can read Zip archives.  <p>Note that {@link ZipArchiveEntry#getSize()} may return -1 if the DEFLATE algorithm is used, as the size information is not available from the header.</p>  <p>The {@link ZipFile} class is preferred when reading from files.</p>  <p>As of Apache Commons Compress it transparently supports Zip64 extensions and thus individual entries and archives larger than 4 GB or with more than 65536 entries.</p>  @see ZipFile @NotThreadSafe ",
            "test_failure_causes": "Based on my analysis of the failed test case, I can identify the following key patterns and recommend a possible defect in the production code:\n\n## Analysis of Test Failure Patterns\n\n**Common Pattern Identified:**\n- The test fails when reading stored (uncompressed) ZIP entries\n- The assertion failure occurs at the first element of the byte array comparison\n- Expected byte value: 100 ('d'), Actual byte value: 0\n- This indicates that the data being read from the stored entry is returning zeros instead of the actual content\n\n**Key Observations:**\n1. The test specifically targets stored (uncompressed) entries (COMPRESS-264)\n2. The entry size is correctly reported as 5 bytes\n3. The failure occurs during content reading, not during entry metadata retrieval\n4. The actual data read contains zeros instead of the expected ASCII characters\n\n## Recommended Possible Defect in Production Code\n\n**Defect Location:** `ZipArchiveInputStream` class\n\n**Likely Root Cause:** The `ZipArchiveInputStream` is not properly handling stored (uncompressed) entries when reading their content data. Specifically, there may be an issue in:\n\n1. **Entry Data Positioning:** The stream might not be correctly positioned at the start of the stored entry's data after reading the entry header.\n\n2. **Stored Entry Processing:** There could be a bug in the method that processes stored entries where it's either:\n   - Skipping the actual data section\n   - Returning empty/zero-filled buffers instead of reading the actual file content\n   - Incorrectly calculating data offsets for stored entries\n\n3. **Buffer Management:** The class might be using an internal buffer that's not being properly populated with the stored entry's data, resulting in the reading of uninitialized (zero) bytes.\n\n**Specific Suspicion:** The `read()` method or data extraction logic in `ZipArchiveInputStream` for stored entries is likely returning zeros because it's either not advancing the underlying stream to the correct position or it's reading from an empty/uninitialized buffer.\n\nThis defect would explain why the entry size is correctly reported (metadata is read properly) but the actual content reading fails with zeros.",
            "test_suite": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStreamTest",
            "score": 9,
            "reason": "#9# This method is very likely to be the best location that needs to be fixed because it handles reading stored (uncompressed) ZIP entries, and the test failure specifically occurs when reading stored entry content. The method contains complex buffer management logic and conditional paths for data descriptor handling that could cause incorrect positioning or zero-byte returns. The test expects actual data but gets zeros, suggesting the method is not properly reading from the underlying stream or managing the buffer state correctly for stored entries."
        },
        {
            "method_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::getNextZipEntry()",
            "method_code": "```java\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (EOFException e) {\n            return null;\n        }\n\n        ZipLong sig = new ZipLong(LFH_BUF);\n        if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            return null;\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        int versionMadeBy = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(LFH_BUF, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(LFH_BUF, off));\n        off += SHORT;\n\n        long time = ZipUtil.dosToJavaTime(ZipLong.getValue(LFH_BUF, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(LFH_BUF, off));\n            off += WORD;\n\n            cSize = new ZipLong(LFH_BUF, off);\n            off += WORD;\n\n            size = new ZipLong(LFH_BUF, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        int fileNameLen = ZipShort.getValue(LFH_BUF, off);\n\n        off += SHORT;\n\n        int extraLen = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n\n        byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n\n        byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        if (current.entry.getCompressedSize() != -1) {\n            if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n                current.in = new UnshrinkingInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\n            } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n                current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        new BoundedInputStream(in, current.entry.getCompressedSize()));\n            }\n        }\n        \n        entriesRead++;\n        return current.entry;\n    }\n\n```",
            "method_doc": "Reads the next ZIP archive entry from the stream. This method calls method \"readFirstLocalFileHeader\" for the first entry and \"readFully\" for subsequent entries to read local file headers, then calls method \"processZip64Extra\" to handle Zip64 extensions.",
            "class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream",
            "class_doc": " Implements an input stream that can read Zip archives.  <p>Note that {@link ZipArchiveEntry#getSize()} may return -1 if the DEFLATE algorithm is used, as the size information is not available from the header.</p>  <p>The {@link ZipFile} class is preferred when reading from files.</p>  <p>As of Apache Commons Compress it transparently supports Zip64 extensions and thus individual entries and archives larger than 4 GB or with more than 65536 entries.</p>  @see ZipFile @NotThreadSafe ",
            "test_failure_causes": "Based on my analysis of the failed test case, I can identify the following key patterns and recommend a possible defect in the production code:\n\n## Analysis of Test Failure Patterns\n\n**Common Pattern Identified:**\n- The test fails when reading stored (uncompressed) ZIP entries\n- The assertion failure occurs at the first element of the byte array comparison\n- Expected byte value: 100 ('d'), Actual byte value: 0\n- This indicates that the data being read from the stored entry is returning zeros instead of the actual content\n\n**Key Observations:**\n1. The test specifically targets stored (uncompressed) entries (COMPRESS-264)\n2. The entry size is correctly reported as 5 bytes\n3. The failure occurs during content reading, not during entry metadata retrieval\n4. The actual data read contains zeros instead of the expected ASCII characters\n\n## Recommended Possible Defect in Production Code\n\n**Defect Location:** `ZipArchiveInputStream` class\n\n**Likely Root Cause:** The `ZipArchiveInputStream` is not properly handling stored (uncompressed) entries when reading their content data. Specifically, there may be an issue in:\n\n1. **Entry Data Positioning:** The stream might not be correctly positioned at the start of the stored entry's data after reading the entry header.\n\n2. **Stored Entry Processing:** There could be a bug in the method that processes stored entries where it's either:\n   - Skipping the actual data section\n   - Returning empty/zero-filled buffers instead of reading the actual file content\n   - Incorrectly calculating data offsets for stored entries\n\n3. **Buffer Management:** The class might be using an internal buffer that's not being properly populated with the stored entry's data, resulting in the reading of uninitialized (zero) bytes.\n\n**Specific Suspicion:** The `read()` method or data extraction logic in `ZipArchiveInputStream` for stored entries is likely returning zeros because it's either not advancing the underlying stream to the correct position or it's reading from an empty/uninitialized buffer.\n\nThis defect would explain why the entry size is correctly reported (metadata is read properly) but the actual content reading fails with zeros.",
            "test_suite": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStreamTest",
            "score": 8,
            "reason": "#8# This method is very likely to be the best location that needs to be fixed because it handles the reading of ZIP entry headers and data streams, and the test failure occurs when reading stored (uncompressed) entry content. The method processes entry metadata correctly but may not properly initialize or position the input stream for stored entries, causing subsequent read operations to return zeros instead of actual data. The issue appears to be in how the method handles the transition from reading entry headers to reading entry data for stored entries."
        },
        {
            "method_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::readFirstLocalFileHeader(byte[])",
            "method_code": "```java\n    private void readFirstLocalFileHeader(byte[] lfh) throws IOException {\n        readFully(lfh);\n        ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n```",
            "method_doc": " Fills the given array with the first local file header and deals with splitting/spanning markers that may prefix the first LFH. ",
            "class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream",
            "class_doc": " Implements an input stream that can read Zip archives.  <p>Note that {@link ZipArchiveEntry#getSize()} may return -1 if the DEFLATE algorithm is used, as the size information is not available from the header.</p>  <p>The {@link ZipFile} class is preferred when reading from files.</p>  <p>As of Apache Commons Compress it transparently supports Zip64 extensions and thus individual entries and archives larger than 4 GB or with more than 65536 entries.</p>  @see ZipFile @NotThreadSafe ",
            "test_failure_causes": "Based on my analysis of the failed test case, I can identify the following key patterns and recommend a possible defect in the production code:\n\n## Analysis of Test Failure Patterns\n\n**Common Pattern Identified:**\n- The test fails when reading stored (uncompressed) ZIP entries\n- The assertion failure occurs at the first element of the byte array comparison\n- Expected byte value: 100 ('d'), Actual byte value: 0\n- This indicates that the data being read from the stored entry is returning zeros instead of the actual content\n\n**Key Observations:**\n1. The test specifically targets stored (uncompressed) entries (COMPRESS-264)\n2. The entry size is correctly reported as 5 bytes\n3. The failure occurs during content reading, not during entry metadata retrieval\n4. The actual data read contains zeros instead of the expected ASCII characters\n\n## Recommended Possible Defect in Production Code\n\n**Defect Location:** `ZipArchiveInputStream` class\n\n**Likely Root Cause:** The `ZipArchiveInputStream` is not properly handling stored (uncompressed) entries when reading their content data. Specifically, there may be an issue in:\n\n1. **Entry Data Positioning:** The stream might not be correctly positioned at the start of the stored entry's data after reading the entry header.\n\n2. **Stored Entry Processing:** There could be a bug in the method that processes stored entries where it's either:\n   - Skipping the actual data section\n   - Returning empty/zero-filled buffers instead of reading the actual file content\n   - Incorrectly calculating data offsets for stored entries\n\n3. **Buffer Management:** The class might be using an internal buffer that's not being properly populated with the stored entry's data, resulting in the reading of uninitialized (zero) bytes.\n\n**Specific Suspicion:** The `read()` method or data extraction logic in `ZipArchiveInputStream` for stored entries is likely returning zeros because it's either not advancing the underlying stream to the correct position or it's reading from an empty/uninitialized buffer.\n\nThis defect would explain why the entry size is correctly reported (metadata is read properly) but the actual content reading fails with zeros.",
            "test_suite": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStreamTest",
            "score": 8,
            "reason": "#8# This method is very likely to be the best location that needs to be fixed because it handles the initial reading of local file headers and deals with split/spanning markers. The test failure occurs when reading stored entries, and this method is responsible for positioning the stream at the correct location for reading entry data. If it incorrectly handles the header reading or buffer copying operations, it could cause the stream to be misaligned, resulting in reading zeros instead of the actual file content. The buffer manipulation using System.arraycopy could be corrupting the stream position or header data, leading to the observed failure where expected data 'd' (100) is replaced by 0."
        },
        {
            "method_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::read(byte[],int,int)",
            "method_code": "```java\n    @Override\n    public int read(byte[] buffer, int offset, int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n        \n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n        \n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n        }\n        \n        return read;\n    }\n\n```",
            "method_doc": "Reads bytes from the current ZIP entry into the buffer. This method calls method \"readStored\" for STORED entries and handles other compression methods.",
            "class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream",
            "class_doc": " Implements an input stream that can read Zip archives.  <p>Note that {@link ZipArchiveEntry#getSize()} may return -1 if the DEFLATE algorithm is used, as the size information is not available from the header.</p>  <p>The {@link ZipFile} class is preferred when reading from files.</p>  <p>As of Apache Commons Compress it transparently supports Zip64 extensions and thus individual entries and archives larger than 4 GB or with more than 65536 entries.</p>  @see ZipFile @NotThreadSafe ",
            "test_failure_causes": "Based on my analysis of the failed test case, I can identify the following key patterns and recommend a possible defect in the production code:\n\n## Analysis of Test Failure Patterns\n\n**Common Pattern Identified:**\n- The test fails when reading stored (uncompressed) ZIP entries\n- The assertion failure occurs at the first element of the byte array comparison\n- Expected byte value: 100 ('d'), Actual byte value: 0\n- This indicates that the data being read from the stored entry is returning zeros instead of the actual content\n\n**Key Observations:**\n1. The test specifically targets stored (uncompressed) entries (COMPRESS-264)\n2. The entry size is correctly reported as 5 bytes\n3. The failure occurs during content reading, not during entry metadata retrieval\n4. The actual data read contains zeros instead of the expected ASCII characters\n\n## Recommended Possible Defect in Production Code\n\n**Defect Location:** `ZipArchiveInputStream` class\n\n**Likely Root Cause:** The `ZipArchiveInputStream` is not properly handling stored (uncompressed) entries when reading their content data. Specifically, there may be an issue in:\n\n1. **Entry Data Positioning:** The stream might not be correctly positioned at the start of the stored entry's data after reading the entry header.\n\n2. **Stored Entry Processing:** There could be a bug in the method that processes stored entries where it's either:\n   - Skipping the actual data section\n   - Returning empty/zero-filled buffers instead of reading the actual file content\n   - Incorrectly calculating data offsets for stored entries\n\n3. **Buffer Management:** The class might be using an internal buffer that's not being properly populated with the stored entry's data, resulting in the reading of uninitialized (zero) bytes.\n\n**Specific Suspicion:** The `read()` method or data extraction logic in `ZipArchiveInputStream` for stored entries is likely returning zeros because it's either not advancing the underlying stream to the correct position or it's reading from an empty/uninitialized buffer.\n\nThis defect would explain why the entry size is correctly reported (metadata is read properly) but the actual content reading fails with zeros.",
            "test_suite": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStreamTest",
            "score": 8,
            "reason": "#8# This method is very likely to be the best location that needs to be fixed because it directly handles the reading of stored ZIP entries through the readStored method call. The test failure shows that stored entries are returning zeros instead of actual data, and this method is the entry point for reading ZIP entry content. The method delegates to readStored for STORED entries, which aligns perfectly with the test case that specifically tests reading of stored entries (COMPRESS-264). The issue likely lies in how the readStored method processes the data or positions the stream."
        },
        {
            "method_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::readFully(byte[])",
            "method_code": "```java\n    private void readFully(byte[] b) throws IOException {\n        int count = IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new EOFException();\n        }\n    }\n\n```",
            "method_doc": "Reads the specified byte array completely from the input stream.",
            "class_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream",
            "class_doc": " Implements an input stream that can read Zip archives.  <p>Note that {@link ZipArchiveEntry#getSize()} may return -1 if the DEFLATE algorithm is used, as the size information is not available from the header.</p>  <p>The {@link ZipFile} class is preferred when reading from files.</p>  <p>As of Apache Commons Compress it transparently supports Zip64 extensions and thus individual entries and archives larger than 4 GB or with more than 65536 entries.</p>  @see ZipFile @NotThreadSafe ",
            "test_failure_causes": "Based on my analysis of the failed test case, I can identify the following key patterns and recommend a possible defect in the production code:\n\n## Analysis of Test Failure Patterns\n\n**Common Pattern Identified:**\n- The test fails when reading stored (uncompressed) ZIP entries\n- The assertion failure occurs at the first element of the byte array comparison\n- Expected byte value: 100 ('d'), Actual byte value: 0\n- This indicates that the data being read from the stored entry is returning zeros instead of the actual content\n\n**Key Observations:**\n1. The test specifically targets stored (uncompressed) entries (COMPRESS-264)\n2. The entry size is correctly reported as 5 bytes\n3. The failure occurs during content reading, not during entry metadata retrieval\n4. The actual data read contains zeros instead of the expected ASCII characters\n\n## Recommended Possible Defect in Production Code\n\n**Defect Location:** `ZipArchiveInputStream` class\n\n**Likely Root Cause:** The `ZipArchiveInputStream` is not properly handling stored (uncompressed) entries when reading their content data. Specifically, there may be an issue in:\n\n1. **Entry Data Positioning:** The stream might not be correctly positioned at the start of the stored entry's data after reading the entry header.\n\n2. **Stored Entry Processing:** There could be a bug in the method that processes stored entries where it's either:\n   - Skipping the actual data section\n   - Returning empty/zero-filled buffers instead of reading the actual file content\n   - Incorrectly calculating data offsets for stored entries\n\n3. **Buffer Management:** The class might be using an internal buffer that's not being properly populated with the stored entry's data, resulting in the reading of uninitialized (zero) bytes.\n\n**Specific Suspicion:** The `read()` method or data extraction logic in `ZipArchiveInputStream` for stored entries is likely returning zeros because it's either not advancing the underlying stream to the correct position or it's reading from an empty/uninitialized buffer.\n\nThis defect would explain why the entry size is correctly reported (metadata is read properly) but the actual content reading fails with zeros.",
            "test_suite": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStreamTest",
            "score": 8,
            "reason": "#8# The readFully method is highly suspicious because it's responsible for reading byte arrays from the input stream, and the test failure shows that the actual data read contains zeros instead of the expected content. The method uses IOUtils.readFully which should populate the byte array with actual data, but if the underlying stream position is incorrect or the buffer management is flawed, it could result in reading zeros. Since the test specifically fails when reading stored entries and the entry size is correct but content is wrong, this method is likely not properly handling the data reading for stored entries."
        }
    ],
    "buggy_codes": {
        "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::getNextZipEntry()": {
            "method_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::getNextZipEntry()",
            "method_code": "```java\n    public ZipArchiveEntry getNextZipEntry() throws IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n\n        try {\n            if (firstEntry) {\n                // split archives have a special signature before the\n                // first local file header - look for it and fail with\n                // the appropriate error message if this is a split\n                // archive.\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (EOFException e) {\n            return null;\n        }\n\n        ZipLong sig = new ZipLong(LFH_BUF);\n        if (sig.equals(ZipLong.CFH_SIG) || sig.equals(ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n        }\n        if (!sig.equals(ZipLong.LFH_SIG)) {\n            return null;\n        }\n\n        int off = WORD;\n        current = new CurrentEntry();\n\n        int versionMadeBy = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n        current.entry.setPlatform((versionMadeBy >> ZipFile.BYTE_SHIFT) & ZipFile.NIBLET_MASK);\n\n        final GeneralPurposeBit gpFlag = GeneralPurposeBit.parse(LFH_BUF, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final ZipEncoding entryEncoding = hasUTF8Flag ? ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n\n        off += SHORT;\n\n        current.entry.setMethod(ZipShort.getValue(LFH_BUF, off));\n        off += SHORT;\n\n        long time = ZipUtil.dosToJavaTime(ZipLong.getValue(LFH_BUF, off));\n        current.entry.setTime(time);\n        off += WORD;\n\n        ZipLong size = null, cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(ZipLong.getValue(LFH_BUF, off));\n            off += WORD;\n\n            cSize = new ZipLong(LFH_BUF, off);\n            off += WORD;\n\n            size = new ZipLong(LFH_BUF, off);\n            off += WORD;\n        } else {\n            off += 3 * WORD;\n        }\n\n        int fileNameLen = ZipShort.getValue(LFH_BUF, off);\n\n        off += SHORT;\n\n        int extraLen = ZipShort.getValue(LFH_BUF, off);\n        off += SHORT;\n\n        byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n\n        byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n\n        if (!hasUTF8Flag && useUnicodeExtraFields) {\n            ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n\n        processZip64Extra(size, cSize);\n\n        if (current.entry.getCompressedSize() != -1) {\n            if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\n                current.in = new UnshrinkingInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\n            } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n                current.in = new ExplodingInputStream(\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\n                        new BoundedInputStream(in, current.entry.getCompressedSize()));\n            }\n        }\n        \n        entriesRead++;\n        return current.entry;\n    }\n\n```",
            "method_doc": "Reads the next ZIP archive entry from the stream. This method calls method \"readFirstLocalFileHeader\" for the first entry and \"readFully\" for subsequent entries to read local file headers, then calls method \"processZip64Extra\" to handle Zip64 extensions."
        },
        "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::readFirstLocalFileHeader(byte[])": {
            "method_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::readFirstLocalFileHeader(byte[])",
            "method_code": "```java\n    private void readFirstLocalFileHeader(byte[] lfh) throws IOException {\n        readFully(lfh);\n        ZipLong sig = new ZipLong(lfh);\n        if (sig.equals(ZipLong.DD_SIG)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n\n        if (sig.equals(ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            // The archive is not really split as only one segment was\n            // needed in the end.  Just skip over the marker.\n            byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            System.arraycopy(lfh, 4, lfh, 0, LFH_LEN - 4);\n            System.arraycopy(missedLfhBytes, 0, lfh, LFH_LEN - 4, 4);\n        }\n    }\n\n```",
            "method_doc": " Fills the given array with the first local file header and deals with splitting/spanning markers that may prefix the first LFH. "
        },
        "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::read(byte[],int,int)": {
            "method_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::read(byte[],int,int)",
            "method_code": "```java\n    @Override\n    public int read(byte[] buffer, int offset, int length) throws IOException {\n        if (closed) {\n            throw new IOException(\"The stream is closed\");\n        }\n\n        if (current == null) {\n            return -1;\n        }\n\n        // avoid int overflow, check null buffer\n        if (offset > buffer.length || length < 0 || offset < 0 || buffer.length - offset < length) {\n            throw new ArrayIndexOutOfBoundsException();\n        }\n        \n        ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new UnsupportedZipFeatureException(UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR,\n                    current.entry);\n        }\n\n        int read;\n        if (current.entry.getMethod() == ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()\n                || current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new UnsupportedZipFeatureException(ZipMethod.getMethodByCode(current.entry.getMethod()),\n                    current.entry);\n        }\n        \n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n        }\n        \n        return read;\n    }\n\n```",
            "method_doc": "Reads bytes from the current ZIP entry into the buffer. This method calls method \"readStored\" for STORED entries and handles other compression methods."
        },
        "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::readStored(byte[],int,int)": {
            "method_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::readStored(byte[],int,int)",
            "method_code": "```java\n    private int readStored(byte[] buffer, int offset, int length) throws IOException {\n\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n\n        long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            int l = in.read(buf.array());\n            if (l == -1) {\n                return -1;\n            }\n            buf.limit(l);\n\n            count(buf.limit());\n            current.bytesReadFromStream += buf.limit();\n        }\n\n        int toRead = Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            // if it is smaller than toRead then it fits into an int\n            toRead = (int) (csize - current.bytesRead);\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n```",
            "method_doc": " Implementation of read for STORED entries. "
        },
        "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::readFully(byte[])": {
            "method_name": "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream::readFully(byte[])",
            "method_code": "```java\n    private void readFully(byte[] b) throws IOException {\n        int count = IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new EOFException();\n        }\n    }\n\n```",
            "method_doc": "Reads the specified byte array completely from the input stream."
        }
    }
}