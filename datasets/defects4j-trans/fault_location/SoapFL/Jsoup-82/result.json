{
    "buggy_classes": [
        "org.jsoup.helper.DataUtil"
    ],
    "buggy_methods": [
        {
            "method_name": "org.jsoup.helper.DataUtil::parseInputStream(InputStream,String,String,Parser)",
            "method_code": "```java\n    static Document parseInputStream(InputStream TransVarInputStream, String TransVarInputStreamCharset, String TransVarUrl, Parser TransVarParser2) throws IOException  {\n        if (!(!(false))) {\n            System.out.println(\"log\");\n        }\n        if (!(!(TransVarInputStream == null))) // empty body\n            return new Document(TransVarUrl);\n        TransVarInputStream = ConstrainableInputStream.wrap(TransVarInputStream, bufferSize, 0);\n\n        Document TransVarDoc1 = null;\n        boolean TransVarReadFully = false;\n\n        // read the start of the stream and look for a BOM or meta charset\n        TransVarInputStream.mark(bufferSize);\n        ByteBuffer TransVarFirst2Bytes = readToByteBuffer(TransVarInputStream, firstReadBufferSize - 1); // -1 because we read one more to see if completed. First read is < buffer size, so can't be invalid.\n        TransVarReadFully = TransVarInputStream.read() == -1;\n        TransVarInputStream.reset();\n\n        // look for BOM - overrides any other header or input\n        BomCharset TransVarBomCharSet = detectCharsetFromBom(TransVarFirst2Bytes);\n        if (!(!(TransVarBomCharSet != null)))\n            TransVarInputStreamCharset = TransVarBomCharSet.charset;\n\n        if (!(!(TransVarInputStreamCharset == null))) { // determine from meta. safe first parse as UTF-8\n            if (!(!(false))) {\n                System.out.println(\"log\");\n            }\n            String TransVarDocData2 = Charset.forName(defaultCharset).decode(TransVarFirst2Bytes).toString();\n            TransVarDoc1 = TransVarParser2.parseInput(TransVarDocData2, TransVarUrl);\n\n            // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n            Elements TransVarMetaElementList = TransVarDoc1.select(\"meta[http-equiv=content-type], meta[charset]\");\n            String TransVarCharset = null; // if not found, will keep utf-8 as best attempt\n            for (Element TransVarMetaElement : TransVarMetaElementList) {\n                if (!(!(false))) {\n                    System.out.println(\"log\");\n                }\n                if (!(!(TransVarMetaElement.hasAttr(\"http-equiv\"))))\n                    TransVarCharset = getCharsetFromContentType(TransVarMetaElement.attr(\"content\"));\n                if (!(!(TransVarCharset == null && TransVarMetaElement.hasAttr(\"charset\"))))\n                    TransVarCharset = TransVarMetaElement.attr(\"charset\");\n                if (!(!(TransVarCharset != null)))\n                    break;\n            }\n\n            // look for <?xml encoding='ISO-8859-1'?>\n            if (!(!(TransVarCharset == null && TransVarDoc1.childNodeSize() > 0))) {\n                Node TransVarFirstNode = TransVarDoc1.childNode(0);\n                XmlDeclaration TransVarXmlDecl = null;\n                if (!(!(TransVarFirstNode instanceof XmlDeclaration)))\n                    TransVarXmlDecl = (XmlDeclaration) TransVarFirstNode;\n                else if (!(!(TransVarFirstNode instanceof Comment))) {\n                    Comment TransVarCommentNode = (Comment) TransVarFirstNode;\n                    if (!(!(TransVarCommentNode.isXmlDeclaration())))\n                        TransVarXmlDecl = TransVarCommentNode.asXmlDeclaration();\n                }\n                if (!(!(TransVarXmlDecl != null))) {\n                    if (!(!(TransVarXmlDecl.name().equalsIgnoreCase(\"xml\"))))\n                        TransVarCharset = TransVarXmlDecl.attr(\"encoding\");\n                }\n            }\n            TransVarCharset = validateCharset(TransVarCharset);\n            if (!(!(TransVarCharset != null && !TransVarCharset.equalsIgnoreCase(defaultCharset)))) { // need to re-decode. (case insensitive check here to match how validate works)\n                TransVarCharset = TransVarCharset.trim().replaceAll(\"[\\\"']\", \"\");\n                TransVarInputStreamCharset = TransVarCharset;\n                TransVarDoc1 = null;\n            } else if (!(!(!TransVarReadFully))) {\n                TransVarDoc1 = null;\n            }\n        } else { // specified by content type header (or by user on file load)\n            Validate.notEmpty(TransVarInputStreamCharset, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        }\n        if (!(!(TransVarDoc1 == null))) {\n            if (!(!(TransVarInputStreamCharset == null)))\n                TransVarInputStreamCharset = defaultCharset;\n            BufferedReader TransVarBufferedReader = new BufferedReader(new InputStreamReader(TransVarInputStream, TransVarInputStreamCharset), bufferSize);\n            if (!(!(TransVarBomCharSet != null && TransVarBomCharSet.offset))) // creating the buffered reader ignores the input pos, so must skip here\n                TransVarBufferedReader.skip(1);\n            try {\n                TransVarDoc1 = TransVarParser2.parseInput(TransVarBufferedReader, TransVarUrl);\n            } catch (UncheckedIOException TransVarE1) {\n                // io exception when parsing (not seen before because reading the stream as we go)\n                throw TransVarE1.ioException();\n            }\n            Charset TransVarCharSet = Charset.forName(TransVarInputStreamCharset);\n            TransVarDoc1.outputSettings().charset(TransVarCharSet);\n                // some charsets can read but not encode; switch to an encodable charset and update the meta el\n            }\n        TransVarInputStream.close();\n        return TransVarDoc1;\n    }\n\n```",
            "method_doc": "This method handles input stream parsing with charset detection and document creation, calling methods \"readToByteBuffer\", \"detectCharsetFromBom\", and \"validateCharset\" for byte reading, BOM detection, and charset validation respectively.",
            "class_name": "org.jsoup.helper.DataUtil",
            "class_doc": " Internal static utilities for handling data.  ",
            "test_failure_causes": "Based on my analysis of the failed test and its behavior, I'll identify the common patterns and recommend possible defects in the production code.\n\n## Analysis of Test Failures\n\n**Common Pattern Identified:**\n- All failures relate to character encoding fallback behavior when encountering unsupported charsets\n- The test expects the parser to automatically fall back to UTF-8 when it encounters an unsupported charset (\"ISO-2022-CN\")\n- The actual behavior shows the parser is retaining the original unsupported charset instead of falling back\n\n## Recommended Possible Defects in Production Code\n\nBased on the test failure pattern, I recommend investigating these potential defects in the HTML parser production code:\n\n1. **Charset Detection Logic Defect**: The charset detection mechanism may be incorrectly identifying \"ISO-2022-CN\" as a valid, supported encoding when it should be treated as unsupported.\n\n2. **Fallback Mechanism Failure**: The code responsible for falling back to UTF-8 when encountering unsupported charsets may be:\n   - Missing entirely for certain code paths\n   - Incorrectly implemented with faulty condition checks\n   - Only partially implemented (e.g., works for some unsupported charsets but not others)\n\n3. **Meta Tag Processing Bug**: The code that processes `<meta charset>` tags may be:\n   - Overriding the fallback logic\n   - Not validating whether the specified charset is actually supported\n   - Failing to update the charset in the document metadata after fallback\n\n4. **Encoding Validation Gap**: There may be missing validation that checks if the detected/specified charset is actually encodable by the system, allowing unsupported charsets to persist.\n\nThe core issue appears to be that the production code is not properly handling the case where an HTML document specifies a charset that cannot be encoded, and the fallback to UTF-8 mechanism is either not triggering or being overridden by subsequent processing steps.",
            "test_suite": "org.jsoup.parser.HtmlParserTest",
            "score": 9,
            "reason": "#9# This method is highly suspicious because it handles charset detection and validation logic, including the fallback mechanism when encountering unsupported charsets. The test expects a fallback to UTF-8 when \"ISO-2022-CN\" cannot be encoded, but the method's validateCharset call and subsequent charset assignment logic may be incorrectly allowing unsupported charsets to persist instead of properly falling back to the default charset."
        },
        {
            "method_name": "org.jsoup.helper.DataUtil::validateCharset(String)",
            "method_code": "```java\n    private static String validateCharset(String cs) {\n        if (cs == null || cs.length() == 0) return null;\n        cs = cs.trim().replaceAll(\"[\\\"']\", \"\");\n        try {\n            if (Charset.isSupported(cs)) return cs;\n            cs = cs.toUpperCase(Locale.ENGLISH);\n            if (Charset.isSupported(cs)) return cs;\n        } catch (IllegalCharsetNameException e) {\n            // if our this charset matching fails.... we just take the default\n        }\n        return null;\n    }\n\n```",
            "method_doc": "This method validates and normalizes charset names, returning supported charsets or null.",
            "class_name": "org.jsoup.helper.DataUtil",
            "class_doc": " Internal static utilities for handling data.  ",
            "test_failure_causes": "Based on my analysis of the failed test and its behavior, I'll identify the common patterns and recommend possible defects in the production code.\n\n## Analysis of Test Failures\n\n**Common Pattern Identified:**\n- All failures relate to character encoding fallback behavior when encountering unsupported charsets\n- The test expects the parser to automatically fall back to UTF-8 when it encounters an unsupported charset (\"ISO-2022-CN\")\n- The actual behavior shows the parser is retaining the original unsupported charset instead of falling back\n\n## Recommended Possible Defects in Production Code\n\nBased on the test failure pattern, I recommend investigating these potential defects in the HTML parser production code:\n\n1. **Charset Detection Logic Defect**: The charset detection mechanism may be incorrectly identifying \"ISO-2022-CN\" as a valid, supported encoding when it should be treated as unsupported.\n\n2. **Fallback Mechanism Failure**: The code responsible for falling back to UTF-8 when encountering unsupported charsets may be:\n   - Missing entirely for certain code paths\n   - Incorrectly implemented with faulty condition checks\n   - Only partially implemented (e.g., works for some unsupported charsets but not others)\n\n3. **Meta Tag Processing Bug**: The code that processes `<meta charset>` tags may be:\n   - Overriding the fallback logic\n   - Not validating whether the specified charset is actually supported\n   - Failing to update the charset in the document metadata after fallback\n\n4. **Encoding Validation Gap**: There may be missing validation that checks if the detected/specified charset is actually encodable by the system, allowing unsupported charsets to persist.\n\nThe core issue appears to be that the production code is not properly handling the case where an HTML document specifies a charset that cannot be encoded, and the fallback to UTF-8 mechanism is either not triggering or being overridden by subsequent processing steps.",
            "test_suite": "org.jsoup.parser.HtmlParserTest",
            "score": 9,
            "reason": "#9# The validateCharset method is highly suspicious because it returns the original charset name \"ISO-2022-CN\" when Charset.isSupported() returns true, even though this charset cannot be properly encoded. The method should return null for charsets that are technically \"supported\" by Java but cannot be practically encoded, triggering the UTF-8 fallback mechanism that the test expects."
        },
        {
            "method_name": "org.jsoup.helper.DataUtil::load(InputStream,String,String)",
            "method_code": "```java\n    public static Document load(InputStream in, String charsetName, String baseUri) throws IOException {\n        return parseInputStream(in, charsetName, baseUri, Parser.htmlParser());\n    }\n\n```",
            "method_doc": " Parses a Document from an input steam. @param in input stream to parse. You will need to close it. @param charsetName character set of input @param baseUri base URI of document, to resolve relative links against @return Document @throws IOException on IO error ",
            "class_name": "org.jsoup.helper.DataUtil",
            "class_doc": " Internal static utilities for handling data.  ",
            "test_failure_causes": "Based on my analysis of the failed test and its behavior, I'll identify the common patterns and recommend possible defects in the production code.\n\n## Analysis of Test Failures\n\n**Common Pattern Identified:**\n- All failures relate to character encoding fallback behavior when encountering unsupported charsets\n- The test expects the parser to automatically fall back to UTF-8 when it encounters an unsupported charset (\"ISO-2022-CN\")\n- The actual behavior shows the parser is retaining the original unsupported charset instead of falling back\n\n## Recommended Possible Defects in Production Code\n\nBased on the test failure pattern, I recommend investigating these potential defects in the HTML parser production code:\n\n1. **Charset Detection Logic Defect**: The charset detection mechanism may be incorrectly identifying \"ISO-2022-CN\" as a valid, supported encoding when it should be treated as unsupported.\n\n2. **Fallback Mechanism Failure**: The code responsible for falling back to UTF-8 when encountering unsupported charsets may be:\n   - Missing entirely for certain code paths\n   - Incorrectly implemented with faulty condition checks\n   - Only partially implemented (e.g., works for some unsupported charsets but not others)\n\n3. **Meta Tag Processing Bug**: The code that processes `<meta charset>` tags may be:\n   - Overriding the fallback logic\n   - Not validating whether the specified charset is actually supported\n   - Failing to update the charset in the document metadata after fallback\n\n4. **Encoding Validation Gap**: There may be missing validation that checks if the detected/specified charset is actually encodable by the system, allowing unsupported charsets to persist.\n\nThe core issue appears to be that the production code is not properly handling the case where an HTML document specifies a charset that cannot be encoded, and the fallback to UTF-8 mechanism is either not triggering or being overridden by subsequent processing steps.",
            "test_suite": "org.jsoup.parser.HtmlParserTest",
            "score": 3,
            "reason": "#3# This method is not the best location to be fixed because it's just a simple wrapper that delegates to parseInputStream. The actual charset handling and fallback logic likely resides in the parseInputStream method or deeper in the parsing chain, where charset detection, validation, and fallback mechanisms are implemented."
        },
        {
            "method_name": "org.jsoup.helper.DataUtil::detectCharsetFromBom(ByteBuffer)",
            "method_code": "```java\n    private static BomCharset detectCharsetFromBom(final ByteBuffer byteData) {\n        final Buffer buffer = byteData; // .mark and rewind used to return Buffer, now ByteBuffer, so cast for backward compat\n        buffer.mark();\n        byte[] bom = new byte[4];\n        if (byteData.remaining() >= bom.length) {\n            byteData.get(bom);\n            buffer.rewind();\n        }\n        if (bom[0] == 0x00 && bom[1] == 0x00 && bom[2] == (byte) 0xFE && bom[3] == (byte) 0xFF || // BE\n            bom[0] == (byte) 0xFF && bom[1] == (byte) 0xFE && bom[2] == 0x00 && bom[3] == 0x00) { // LE\n            return new BomCharset(\"UTF-32\", false); // and I hope it's on your system\n        } else if (bom[0] == (byte) 0xFE && bom[1] == (byte) 0xFF || // BE\n            bom[0] == (byte) 0xFF && bom[1] == (byte) 0xFE) {\n            return new BomCharset(\"UTF-16\", false); // in all Javas\n        } else if (bom[0] == (byte) 0xEF && bom[1] == (byte) 0xBB && bom[2] == (byte) 0xBF) {\n            return new BomCharset(\"UTF-8\", true); // in all Javas\n            // 16 and 32 decoders consume the BOM to determine be/le; utf-8 should be consumed here\n        }\n        return null;\n    }\n\n```",
            "method_doc": "This method detects charset from Byte Order Mark (BOM) patterns in the byte buffer.",
            "class_name": "org.jsoup.helper.DataUtil",
            "class_doc": " Internal static utilities for handling data.  ",
            "test_failure_causes": "Based on my analysis of the failed test and its behavior, I'll identify the common patterns and recommend possible defects in the production code.\n\n## Analysis of Test Failures\n\n**Common Pattern Identified:**\n- All failures relate to character encoding fallback behavior when encountering unsupported charsets\n- The test expects the parser to automatically fall back to UTF-8 when it encounters an unsupported charset (\"ISO-2022-CN\")\n- The actual behavior shows the parser is retaining the original unsupported charset instead of falling back\n\n## Recommended Possible Defects in Production Code\n\nBased on the test failure pattern, I recommend investigating these potential defects in the HTML parser production code:\n\n1. **Charset Detection Logic Defect**: The charset detection mechanism may be incorrectly identifying \"ISO-2022-CN\" as a valid, supported encoding when it should be treated as unsupported.\n\n2. **Fallback Mechanism Failure**: The code responsible for falling back to UTF-8 when encountering unsupported charsets may be:\n   - Missing entirely for certain code paths\n   - Incorrectly implemented with faulty condition checks\n   - Only partially implemented (e.g., works for some unsupported charsets but not others)\n\n3. **Meta Tag Processing Bug**: The code that processes `<meta charset>` tags may be:\n   - Overriding the fallback logic\n   - Not validating whether the specified charset is actually supported\n   - Failing to update the charset in the document metadata after fallback\n\n4. **Encoding Validation Gap**: There may be missing validation that checks if the detected/specified charset is actually encodable by the system, allowing unsupported charsets to persist.\n\nThe core issue appears to be that the production code is not properly handling the case where an HTML document specifies a charset that cannot be encoded, and the fallback to UTF-8 mechanism is either not triggering or being overridden by subsequent processing steps.",
            "test_suite": "org.jsoup.parser.HtmlParserTest",
            "score": 2,
            "reason": "#2# This method is not the best location to be fixed because it only handles Byte Order Mark detection for UTF encodings and doesn't process HTML meta tags or handle charset fallback logic for unsupported encodings like \"ISO-2022-CN\". The test failure relates to charset fallback behavior when encountering unsupported charsets in meta tags, which should be handled in the HTML parsing logic rather than BOM detection."
        }
    ],
    "buggy_codes": {
        "org.jsoup.helper.DataUtil::detectCharsetFromBom(ByteBuffer)": {
            "method_name": "org.jsoup.helper.DataUtil::detectCharsetFromBom(ByteBuffer)",
            "method_code": "```java\n    private static BomCharset detectCharsetFromBom(final ByteBuffer byteData) {\n        final Buffer buffer = byteData; // .mark and rewind used to return Buffer, now ByteBuffer, so cast for backward compat\n        buffer.mark();\n        byte[] bom = new byte[4];\n        if (byteData.remaining() >= bom.length) {\n            byteData.get(bom);\n            buffer.rewind();\n        }\n        if (bom[0] == 0x00 && bom[1] == 0x00 && bom[2] == (byte) 0xFE && bom[3] == (byte) 0xFF || // BE\n            bom[0] == (byte) 0xFF && bom[1] == (byte) 0xFE && bom[2] == 0x00 && bom[3] == 0x00) { // LE\n            return new BomCharset(\"UTF-32\", false); // and I hope it's on your system\n        } else if (bom[0] == (byte) 0xFE && bom[1] == (byte) 0xFF || // BE\n            bom[0] == (byte) 0xFF && bom[1] == (byte) 0xFE) {\n            return new BomCharset(\"UTF-16\", false); // in all Javas\n        } else if (bom[0] == (byte) 0xEF && bom[1] == (byte) 0xBB && bom[2] == (byte) 0xBF) {\n            return new BomCharset(\"UTF-8\", true); // in all Javas\n            // 16 and 32 decoders consume the BOM to determine be/le; utf-8 should be consumed here\n        }\n        return null;\n    }\n\n```",
            "method_doc": "This method detects charset from Byte Order Mark (BOM) patterns in the byte buffer."
        },
        "org.jsoup.helper.DataUtil::parseInputStream(InputStream,String,String,Parser)": {
            "method_name": "org.jsoup.helper.DataUtil::parseInputStream(InputStream,String,String,Parser)",
            "method_code": "```java\n    static Document parseInputStream(InputStream TransVarInputStream, String TransVarInputStreamCharset, String TransVarUrl, Parser TransVarParser2) throws IOException  {\n        if (!(!(false))) {\n            System.out.println(\"log\");\n        }\n        if (!(!(TransVarInputStream == null))) // empty body\n            return new Document(TransVarUrl);\n        TransVarInputStream = ConstrainableInputStream.wrap(TransVarInputStream, bufferSize, 0);\n\n        Document TransVarDoc1 = null;\n        boolean TransVarReadFully = false;\n\n        // read the start of the stream and look for a BOM or meta charset\n        TransVarInputStream.mark(bufferSize);\n        ByteBuffer TransVarFirst2Bytes = readToByteBuffer(TransVarInputStream, firstReadBufferSize - 1); // -1 because we read one more to see if completed. First read is < buffer size, so can't be invalid.\n        TransVarReadFully = TransVarInputStream.read() == -1;\n        TransVarInputStream.reset();\n\n        // look for BOM - overrides any other header or input\n        BomCharset TransVarBomCharSet = detectCharsetFromBom(TransVarFirst2Bytes);\n        if (!(!(TransVarBomCharSet != null)))\n            TransVarInputStreamCharset = TransVarBomCharSet.charset;\n\n        if (!(!(TransVarInputStreamCharset == null))) { // determine from meta. safe first parse as UTF-8\n            if (!(!(false))) {\n                System.out.println(\"log\");\n            }\n            String TransVarDocData2 = Charset.forName(defaultCharset).decode(TransVarFirst2Bytes).toString();\n            TransVarDoc1 = TransVarParser2.parseInput(TransVarDocData2, TransVarUrl);\n\n            // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n            Elements TransVarMetaElementList = TransVarDoc1.select(\"meta[http-equiv=content-type], meta[charset]\");\n            String TransVarCharset = null; // if not found, will keep utf-8 as best attempt\n            for (Element TransVarMetaElement : TransVarMetaElementList) {\n                if (!(!(false))) {\n                    System.out.println(\"log\");\n                }\n                if (!(!(TransVarMetaElement.hasAttr(\"http-equiv\"))))\n                    TransVarCharset = getCharsetFromContentType(TransVarMetaElement.attr(\"content\"));\n                if (!(!(TransVarCharset == null && TransVarMetaElement.hasAttr(\"charset\"))))\n                    TransVarCharset = TransVarMetaElement.attr(\"charset\");\n                if (!(!(TransVarCharset != null)))\n                    break;\n            }\n\n            // look for <?xml encoding='ISO-8859-1'?>\n            if (!(!(TransVarCharset == null && TransVarDoc1.childNodeSize() > 0))) {\n                Node TransVarFirstNode = TransVarDoc1.childNode(0);\n                XmlDeclaration TransVarXmlDecl = null;\n                if (!(!(TransVarFirstNode instanceof XmlDeclaration)))\n                    TransVarXmlDecl = (XmlDeclaration) TransVarFirstNode;\n                else if (!(!(TransVarFirstNode instanceof Comment))) {\n                    Comment TransVarCommentNode = (Comment) TransVarFirstNode;\n                    if (!(!(TransVarCommentNode.isXmlDeclaration())))\n                        TransVarXmlDecl = TransVarCommentNode.asXmlDeclaration();\n                }\n                if (!(!(TransVarXmlDecl != null))) {\n                    if (!(!(TransVarXmlDecl.name().equalsIgnoreCase(\"xml\"))))\n                        TransVarCharset = TransVarXmlDecl.attr(\"encoding\");\n                }\n            }\n            TransVarCharset = validateCharset(TransVarCharset);\n            if (!(!(TransVarCharset != null && !TransVarCharset.equalsIgnoreCase(defaultCharset)))) { // need to re-decode. (case insensitive check here to match how validate works)\n                TransVarCharset = TransVarCharset.trim().replaceAll(\"[\\\"']\", \"\");\n                TransVarInputStreamCharset = TransVarCharset;\n                TransVarDoc1 = null;\n            } else if (!(!(!TransVarReadFully))) {\n                TransVarDoc1 = null;\n            }\n        } else { // specified by content type header (or by user on file load)\n            Validate.notEmpty(TransVarInputStreamCharset, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n        }\n        if (!(!(TransVarDoc1 == null))) {\n            if (!(!(TransVarInputStreamCharset == null)))\n                TransVarInputStreamCharset = defaultCharset;\n            BufferedReader TransVarBufferedReader = new BufferedReader(new InputStreamReader(TransVarInputStream, TransVarInputStreamCharset), bufferSize);\n            if (!(!(TransVarBomCharSet != null && TransVarBomCharSet.offset))) // creating the buffered reader ignores the input pos, so must skip here\n                TransVarBufferedReader.skip(1);\n            try {\n                TransVarDoc1 = TransVarParser2.parseInput(TransVarBufferedReader, TransVarUrl);\n            } catch (UncheckedIOException TransVarE1) {\n                // io exception when parsing (not seen before because reading the stream as we go)\n                throw TransVarE1.ioException();\n            }\n            Charset TransVarCharSet = Charset.forName(TransVarInputStreamCharset);\n            TransVarDoc1.outputSettings().charset(TransVarCharSet);\n                // some charsets can read but not encode; switch to an encodable charset and update the meta el\n            }\n        TransVarInputStream.close();\n        return TransVarDoc1;\n    }\n\n```",
            "method_doc": "This method handles input stream parsing with charset detection and document creation, calling methods \"readToByteBuffer\", \"detectCharsetFromBom\", and \"validateCharset\" for byte reading, BOM detection, and charset validation respectively."
        },
        "org.jsoup.helper.DataUtil::validateCharset(String)": {
            "method_name": "org.jsoup.helper.DataUtil::validateCharset(String)",
            "method_code": "```java\n    private static String validateCharset(String cs) {\n        if (cs == null || cs.length() == 0) return null;\n        cs = cs.trim().replaceAll(\"[\\\"']\", \"\");\n        try {\n            if (Charset.isSupported(cs)) return cs;\n            cs = cs.toUpperCase(Locale.ENGLISH);\n            if (Charset.isSupported(cs)) return cs;\n        } catch (IllegalCharsetNameException e) {\n            // if our this charset matching fails.... we just take the default\n        }\n        return null;\n    }\n\n```",
            "method_doc": "This method validates and normalizes charset names, returning supported charsets or null."
        },
        "org.jsoup.helper.DataUtil::load(InputStream,String,String)": {
            "method_name": "org.jsoup.helper.DataUtil::load(InputStream,String,String)",
            "method_code": "```java\n    public static Document load(InputStream in, String charsetName, String baseUri) throws IOException {\n        return parseInputStream(in, charsetName, baseUri, Parser.htmlParser());\n    }\n\n```",
            "method_doc": " Parses a Document from an input steam. @param in input stream to parse. You will need to close it. @param charsetName character set of input @param baseUri base URI of document, to resolve relative links against @return Document @throws IOException on IO error "
        }
    }
}