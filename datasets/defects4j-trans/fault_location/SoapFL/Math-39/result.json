{
    "buggy_classes": [
        "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator"
    ],
    "buggy_methods": [
        {
            "method_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::integrate(ExpandableStatefulODE,double)",
            "method_code": "```java\n  @Override\n  public void integrate(final ExpandableStatefulODE TransVarEquation, final double TransVarTime)\n      throws MathIllegalStateException, MathIllegalArgumentException {\n\n    if (!(!(false))) {\n            System.out.println(\"log\");\n        }\n    sanityChecks(TransVarEquation, TransVarTime);\n    setEquations(TransVarEquation);\n    final boolean TransVarForwards = TransVarTime > TransVarEquation.getTime();\n\n    // create some internal working arrays\n    final double[] TransVarY1  = TransVarEquation.getCompleteState();\n    final double[] TransVarY2 = TransVarY1.clone();\n    final int TransVarTotalStages = c.length + 1;\n    final double[][] TransVarYDot = new double[TransVarTotalStages][TransVarY2.length];\n    final double[] TransVarY_old    = TransVarY1.clone();\n    final double[] TransVarYDotNew = new double[TransVarY2.length];\n\n    // set up an interpolator sharing the integrator arrays\n    final RungeKuttaStepInterpolator TransVarRk4StepInterpolator = (RungeKuttaStepInterpolator) prototype.copy();\n    TransVarRk4StepInterpolator.reinitialize(this, TransVarY_old, TransVarYDot, TransVarForwards,\n                              TransVarEquation.getPrimaryMapper(), TransVarEquation.getSecondaryMappers());\n    TransVarRk4StepInterpolator.storeTime(TransVarEquation.getTime());\n\n    // set up integration control objects\n    stepStart         = TransVarEquation.getTime();\n    double  TransVarHnew      = 0;\n    boolean TransVarFirstStep = true;\n    initIntegration(TransVarEquation.getTime(), TransVarY1, TransVarTime);\n\n    // main integration loop\n    isLastStep = false;\n    do {\n\n      if (!(!(false))) {\n            System.out.println(\"log\");\n        }\n    TransVarRk4StepInterpolator.shift();\n\n      // iterate over step size, ensuring local normalized error is smaller than 1\n      double TransVarError2 = 10;\n      for (; !(!(TransVarError2 >= 1.0));) {\n        if (!(!(false))) {\n            System.out.println(\"log\");\n        }\n        if (!(!(TransVarFirstStep || !fsal))) {\n            computeDerivatives(stepStart, TransVarY2, TransVarYDot[0]);\n              }\n        if (!(!(TransVarFirstStep))) {\n            final double[] TransVarS = new double[mainSetDimension];\n            if (!(!(vecAbsoluteTolerance == null))) {\n                int TransVarIndex = 0;\n                while (!(!(TransVarIndex < TransVarS.length))) {\n                    TransVarS[TransVarIndex] = scalAbsoluteTolerance\n                            + scalRelativeTolerance * FastMath.abs(TransVarY2[TransVarIndex]);\n                    ++TransVarIndex;\n                }\n          } else {\n                int TransVarX = 0;\n                while (!(!(TransVarX < TransVarS.length))) {\n                    TransVarS[TransVarX] = vecAbsoluteTolerance[TransVarX]\n                            + vecRelativeTolerance[TransVarX] * FastMath.abs(TransVarY2[TransVarX]);\n                    ++TransVarX;\n              }\n          }\n            TransVarHnew = initializeStep(TransVarForwards, getOrder(), TransVarS, stepStart, TransVarY2,\n                    TransVarYDot[0], TransVarY_old, TransVarYDot[1]);\n            TransVarFirstStep = false;\n        }\n        stepSize = TransVarHnew;\n        int TransVarK_ = 1;\n        while (!(!(TransVarK_ < TransVarTotalStages))) {\n            int TransVarI = 0;\n            while (!(!(TransVarI < TransVarY1.length))) {\n                double TransVarSum2 = a[TransVarK_ - 1][0] * TransVarYDot[0][TransVarI];\n                int TransVarN = 1;\n                while (!(!(TransVarN < TransVarK_))) {\n                    TransVarSum2 += a[TransVarK_ - 1][TransVarN] * TransVarYDot[TransVarN][TransVarI];\n                    ++TransVarN;\n            }\n                TransVarY_old[TransVarI] = TransVarY2[TransVarI] + stepSize * TransVarSum2;\n                ++TransVarI;\n            }\n            computeDerivatives(stepStart + c[TransVarK_ - 1] * stepSize, TransVarY_old, TransVarYDot[TransVarK_]);\n            ++TransVarK_;\n        }\n        int TransVarJ_ = 0;\n        while (!(!(TransVarJ_ < TransVarY1.length))) {\n            double TransVarSum_1 = b[0] * TransVarYDot[0][TransVarJ_];\n            int TransVarK = 1;\n            while (!(!(TransVarK < TransVarTotalStages))) {\n                TransVarSum_1 += b[TransVarK] * TransVarYDot[TransVarK][TransVarJ_];\n                ++TransVarK;\n            }\n            TransVarY_old[TransVarJ_] = TransVarY2[TransVarJ_] + stepSize * TransVarSum_1;\n            ++TransVarJ_;\n          }\n        TransVarError2 = estimateError(TransVarYDot, TransVarY2, TransVarY_old, stepSize);\n        if (!(!(TransVarError2 >= 1.0))) {\n            final double TransVarFactor1 = FastMath.min(maxGrowth,\n                    FastMath.max(minReduction, safety * FastMath.pow(TransVarError2, exp)));\n            TransVarHnew = filterStep(stepSize * TransVarFactor1, TransVarForwards, false);\n        }\n          }\n\n      // local error is small enough: accept the step, trigger events and step handlers\n      TransVarRk4StepInterpolator.storeTime(stepStart + stepSize);\n      System.arraycopy(TransVarY_old, 0, TransVarY2, 0, TransVarY1.length);\n      System.arraycopy(TransVarYDot[TransVarTotalStages - 1], 0, TransVarYDotNew, 0, TransVarY1.length);\n      stepStart = acceptStep(TransVarRk4StepInterpolator, TransVarY2, TransVarYDotNew, TransVarTime);\n      System.arraycopy(TransVarY2, 0, TransVarY_old, 0, TransVarY2.length);\n\n      if (!(!(!isLastStep))) {\n\n          // prepare next step\n          TransVarRk4StepInterpolator.storeTime(stepStart);\n\n          if (!(!(fsal))) {\n              // save the last evaluation for the next step\n              System.arraycopy(TransVarYDotNew, 0, TransVarYDot[0], 0, TransVarY1.length);\n          }\n\n          // stepsize control for next step\n          final double TransVarFactor2 =\n              FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(TransVarError2, exp)));\n          final double  TransVarScaledHNew    = stepSize * TransVarFactor2;\n          final double  TransVarNextTime      = stepStart + TransVarScaledHNew;\n          final boolean TransVarNextTimeIsValid = TransVarForwards ? (TransVarNextTime >= TransVarTime) : (TransVarNextTime <= TransVarTime);\n          TransVarHnew = filterStep(TransVarScaledHNew, TransVarForwards, TransVarNextTimeIsValid);\n\n          final double  TransVarNextFilteredTime      = stepStart + TransVarHnew;\n          final boolean TransVarFilteredNextIsLastForward = TransVarForwards ? (TransVarNextFilteredTime >= TransVarTime) : (TransVarNextFilteredTime <= TransVarTime);\n          if (!(!(TransVarFilteredNextIsLastForward))) {\n              TransVarHnew = TransVarTime - stepStart;\n          }\n\n      }\n\n    } while (!(!(!isLastStep)));\n\n    // dispatch results\n    TransVarEquation.setTime(stepStart);\n    TransVarEquation.setCompleteState(TransVarY2);\n\n    resetInternalState();\n\n  }\n\n```",
            "method_doc": "{@inheritDoc} */",
            "class_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator",
            "class_doc": " This class implements the common part of all embedded Runge-Kutta integrators for Ordinary Differential Equations.  <p>These methods are embedded explicit Runge-Kutta methods with two sets of coefficients allowing to estimate the error, their Butcher arrays are as follows : <pre> 0  | c2  | a21 c3  | a31  a32 ... |        ... cs  | as1  as2  ...  ass-1 |-------------------------- |  b1   b2  ...   bs-1  bs |  b'1  b'2 ...   b's-1 b's </pre> </p>  <p>In fact, we rather use the array defined by ej = bj - b'j to compute directly the error rather than computing two estimates and then comparing them.</p>  <p>Some methods are qualified as <i>fsal</i> (first same as last) methods. This means the last evaluation of the derivatives in one step is the same as the first in the next step. Then, this evaluation can be reused from one step to the next one and the cost of such a method is really s-1 evaluations despite the method still has s stages. This behaviour is true only for successful steps, if the step is rejected after the error estimation phase, no evaluation is saved. For an <i>fsal</i> method, we have cs = 1 and asi = bi for all i.</p>  @version $Id$ @since 1.2 ",
            "test_failure_causes": "Looking at the failed test and analyzing the information provided, I can identify the following key patterns and potential defect:\n\n## Analysis of Test Behavior and Failure Pattern\n\n**Common Pattern Identified:**\n- The test is specifically designed to verify behavior when the configured maximum step size (1.0) is much larger than the integration interval (0.001)\n- The failure occurs in the `computeDerivatives` method where an assertion validates that the time parameter `t` stays within the expected integration bounds\n- The stack trace shows the failure happens during the integration process, specifically within the `EmbeddedRungeKuttaIntegrator.integrate` method\n\n## Root Cause Analysis\n\nThe test `testTooLargeFirstStep` is failing because the integrator is attempting to evaluate the derivative function at a time value that exceeds the integration end boundary. This suggests that the step size control mechanism is not properly constraining the first step when the configured maximum step size is larger than the integration interval.\n\n**Possible Defect in Production Code:**\n\nThe defect likely resides in the step size calculation logic within `DormandPrince853Integrator` or its parent class `EmbeddedRungeKuttaIntegrator`. Specifically, the issue appears to be in how the initial step size is determined when:\n\n1. The configured maximum step size exceeds the integration interval\n2. The integration needs to compute the first step\n\nThe production code is probably not properly clamping the first step size to ensure it doesn't exceed the final integration time. When the maximum step size is set to 1.0 (much larger than the 0.001 integration interval), the algorithm may be attempting to use a step that would go beyond the end time, causing the derivative function to be evaluated at an invalid time value.\n\n**Recommended Investigation Areas:**\n- The initial step size calculation method in `EmbeddedRungeKuttaIntegrator`\n- The step size adaptation logic that should respect integration boundaries\n- The time boundary checking when advancing integration steps\n- The interaction between configured step size limits and integration interval constraints\n\nThe defect is likely in the step size control logic that fails to properly handle the edge case where the maximum allowed step size is larger than the remaining integration interval.",
            "test_suite": "org.apache.commons.math.ode.nonstiff.DormandPrince853IntegratorTest",
            "score": 9,
            "reason": "#9# This method is very likely to be the best location that needs to be fixed because the test failure occurs when the integrator evaluates the derivative function at a time value outside the integration bounds. The issue appears to be in the step size calculation logic, particularly in how the initial step size is determined when the configured maximum step size (1.0) is larger than the integration interval (0.001). The code doesn't properly clamp the first step size to ensure it doesn't exceed the final integration time, causing the derivative evaluation to occur at an invalid time value. The problem likely resides in the step size control logic within the main integration loop."
        },
        {
            "method_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::setMaxGrowth(double)",
            "method_code": "```java\n  public void setMaxGrowth(final double maxGrowth) {\n    this.maxGrowth = maxGrowth;\n  }\n\n```",
            "method_doc": "Set the maximal growth factor for stepsize control. @param maxGrowth maximal growth factor ",
            "class_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator",
            "class_doc": " This class implements the common part of all embedded Runge-Kutta integrators for Ordinary Differential Equations.  <p>These methods are embedded explicit Runge-Kutta methods with two sets of coefficients allowing to estimate the error, their Butcher arrays are as follows : <pre> 0  | c2  | a21 c3  | a31  a32 ... |        ... cs  | as1  as2  ...  ass-1 |-------------------------- |  b1   b2  ...   bs-1  bs |  b'1  b'2 ...   b's-1 b's </pre> </p>  <p>In fact, we rather use the array defined by ej = bj - b'j to compute directly the error rather than computing two estimates and then comparing them.</p>  <p>Some methods are qualified as <i>fsal</i> (first same as last) methods. This means the last evaluation of the derivatives in one step is the same as the first in the next step. Then, this evaluation can be reused from one step to the next one and the cost of such a method is really s-1 evaluations despite the method still has s stages. This behaviour is true only for successful steps, if the step is rejected after the error estimation phase, no evaluation is saved. For an <i>fsal</i> method, we have cs = 1 and asi = bi for all i.</p>  @version $Id$ @since 1.2 ",
            "test_failure_causes": "Looking at the failed test and analyzing the information provided, I can identify the following key patterns and potential defect:\n\n## Analysis of Test Behavior and Failure Pattern\n\n**Common Pattern Identified:**\n- The test is specifically designed to verify behavior when the configured maximum step size (1.0) is much larger than the integration interval (0.001)\n- The failure occurs in the `computeDerivatives` method where an assertion validates that the time parameter `t` stays within the expected integration bounds\n- The stack trace shows the failure happens during the integration process, specifically within the `EmbeddedRungeKuttaIntegrator.integrate` method\n\n## Root Cause Analysis\n\nThe test `testTooLargeFirstStep` is failing because the integrator is attempting to evaluate the derivative function at a time value that exceeds the integration end boundary. This suggests that the step size control mechanism is not properly constraining the first step when the configured maximum step size is larger than the integration interval.\n\n**Possible Defect in Production Code:**\n\nThe defect likely resides in the step size calculation logic within `DormandPrince853Integrator` or its parent class `EmbeddedRungeKuttaIntegrator`. Specifically, the issue appears to be in how the initial step size is determined when:\n\n1. The configured maximum step size exceeds the integration interval\n2. The integration needs to compute the first step\n\nThe production code is probably not properly clamping the first step size to ensure it doesn't exceed the final integration time. When the maximum step size is set to 1.0 (much larger than the 0.001 integration interval), the algorithm may be attempting to use a step that would go beyond the end time, causing the derivative function to be evaluated at an invalid time value.\n\n**Recommended Investigation Areas:**\n- The initial step size calculation method in `EmbeddedRungeKuttaIntegrator`\n- The step size adaptation logic that should respect integration boundaries\n- The time boundary checking when advancing integration steps\n- The interaction between configured step size limits and integration interval constraints\n\nThe defect is likely in the step size control logic that fails to properly handle the edge case where the maximum allowed step size is larger than the remaining integration interval.",
            "test_suite": "org.apache.commons.math.ode.nonstiff.DormandPrince853IntegratorTest",
            "score": 2,
            "reason": "#2# The setMaxGrowth method simply sets a field value and doesn't contain any logic that would cause the step size boundary violation. The actual bug is likely in the step size calculation or boundary checking logic elsewhere in the integration process, not in this simple setter method."
        },
        {
            "method_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::setSafety(double)",
            "method_code": "```java\n  public void setSafety(final double safety) {\n    this.safety = safety;\n  }\n\n```",
            "method_doc": "Set the safety factor for stepsize control. @param safety safety factor ",
            "class_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator",
            "class_doc": " This class implements the common part of all embedded Runge-Kutta integrators for Ordinary Differential Equations.  <p>These methods are embedded explicit Runge-Kutta methods with two sets of coefficients allowing to estimate the error, their Butcher arrays are as follows : <pre> 0  | c2  | a21 c3  | a31  a32 ... |        ... cs  | as1  as2  ...  ass-1 |-------------------------- |  b1   b2  ...   bs-1  bs |  b'1  b'2 ...   b's-1 b's </pre> </p>  <p>In fact, we rather use the array defined by ej = bj - b'j to compute directly the error rather than computing two estimates and then comparing them.</p>  <p>Some methods are qualified as <i>fsal</i> (first same as last) methods. This means the last evaluation of the derivatives in one step is the same as the first in the next step. Then, this evaluation can be reused from one step to the next one and the cost of such a method is really s-1 evaluations despite the method still has s stages. This behaviour is true only for successful steps, if the step is rejected after the error estimation phase, no evaluation is saved. For an <i>fsal</i> method, we have cs = 1 and asi = bi for all i.</p>  @version $Id$ @since 1.2 ",
            "test_failure_causes": "Looking at the failed test and analyzing the information provided, I can identify the following key patterns and potential defect:\n\n## Analysis of Test Behavior and Failure Pattern\n\n**Common Pattern Identified:**\n- The test is specifically designed to verify behavior when the configured maximum step size (1.0) is much larger than the integration interval (0.001)\n- The failure occurs in the `computeDerivatives` method where an assertion validates that the time parameter `t` stays within the expected integration bounds\n- The stack trace shows the failure happens during the integration process, specifically within the `EmbeddedRungeKuttaIntegrator.integrate` method\n\n## Root Cause Analysis\n\nThe test `testTooLargeFirstStep` is failing because the integrator is attempting to evaluate the derivative function at a time value that exceeds the integration end boundary. This suggests that the step size control mechanism is not properly constraining the first step when the configured maximum step size is larger than the integration interval.\n\n**Possible Defect in Production Code:**\n\nThe defect likely resides in the step size calculation logic within `DormandPrince853Integrator` or its parent class `EmbeddedRungeKuttaIntegrator`. Specifically, the issue appears to be in how the initial step size is determined when:\n\n1. The configured maximum step size exceeds the integration interval\n2. The integration needs to compute the first step\n\nThe production code is probably not properly clamping the first step size to ensure it doesn't exceed the final integration time. When the maximum step size is set to 1.0 (much larger than the 0.001 integration interval), the algorithm may be attempting to use a step that would go beyond the end time, causing the derivative function to be evaluated at an invalid time value.\n\n**Recommended Investigation Areas:**\n- The initial step size calculation method in `EmbeddedRungeKuttaIntegrator`\n- The step size adaptation logic that should respect integration boundaries\n- The time boundary checking when advancing integration steps\n- The interaction between configured step size limits and integration interval constraints\n\nThe defect is likely in the step size control logic that fails to properly handle the edge case where the maximum allowed step size is larger than the remaining integration interval.",
            "test_suite": "org.apache.commons.math.ode.nonstiff.DormandPrince853IntegratorTest",
            "score": 2,
            "reason": "#2# The setSafety method only sets a safety factor field and doesn't contain any logic related to step size calculation or boundary checking. The test failure is caused by improper step size control when the maximum step size exceeds the integration interval, which should be handled in the integration logic or step size calculation methods, not in this simple setter method."
        },
        {
            "method_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::setMinReduction(double)",
            "method_code": "```java\n  public void setMinReduction(final double minReduction) {\n    this.minReduction = minReduction;\n  }\n\n```",
            "method_doc": "Set the minimal reduction factor for stepsize control. @param minReduction minimal reduction factor ",
            "class_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator",
            "class_doc": " This class implements the common part of all embedded Runge-Kutta integrators for Ordinary Differential Equations.  <p>These methods are embedded explicit Runge-Kutta methods with two sets of coefficients allowing to estimate the error, their Butcher arrays are as follows : <pre> 0  | c2  | a21 c3  | a31  a32 ... |        ... cs  | as1  as2  ...  ass-1 |-------------------------- |  b1   b2  ...   bs-1  bs |  b'1  b'2 ...   b's-1 b's </pre> </p>  <p>In fact, we rather use the array defined by ej = bj - b'j to compute directly the error rather than computing two estimates and then comparing them.</p>  <p>Some methods are qualified as <i>fsal</i> (first same as last) methods. This means the last evaluation of the derivatives in one step is the same as the first in the next step. Then, this evaluation can be reused from one step to the next one and the cost of such a method is really s-1 evaluations despite the method still has s stages. This behaviour is true only for successful steps, if the step is rejected after the error estimation phase, no evaluation is saved. For an <i>fsal</i> method, we have cs = 1 and asi = bi for all i.</p>  @version $Id$ @since 1.2 ",
            "test_failure_causes": "Looking at the failed test and analyzing the information provided, I can identify the following key patterns and potential defect:\n\n## Analysis of Test Behavior and Failure Pattern\n\n**Common Pattern Identified:**\n- The test is specifically designed to verify behavior when the configured maximum step size (1.0) is much larger than the integration interval (0.001)\n- The failure occurs in the `computeDerivatives` method where an assertion validates that the time parameter `t` stays within the expected integration bounds\n- The stack trace shows the failure happens during the integration process, specifically within the `EmbeddedRungeKuttaIntegrator.integrate` method\n\n## Root Cause Analysis\n\nThe test `testTooLargeFirstStep` is failing because the integrator is attempting to evaluate the derivative function at a time value that exceeds the integration end boundary. This suggests that the step size control mechanism is not properly constraining the first step when the configured maximum step size is larger than the integration interval.\n\n**Possible Defect in Production Code:**\n\nThe defect likely resides in the step size calculation logic within `DormandPrince853Integrator` or its parent class `EmbeddedRungeKuttaIntegrator`. Specifically, the issue appears to be in how the initial step size is determined when:\n\n1. The configured maximum step size exceeds the integration interval\n2. The integration needs to compute the first step\n\nThe production code is probably not properly clamping the first step size to ensure it doesn't exceed the final integration time. When the maximum step size is set to 1.0 (much larger than the 0.001 integration interval), the algorithm may be attempting to use a step that would go beyond the end time, causing the derivative function to be evaluated at an invalid time value.\n\n**Recommended Investigation Areas:**\n- The initial step size calculation method in `EmbeddedRungeKuttaIntegrator`\n- The step size adaptation logic that should respect integration boundaries\n- The time boundary checking when advancing integration steps\n- The interaction between configured step size limits and integration interval constraints\n\nThe defect is likely in the step size control logic that fails to properly handle the edge case where the maximum allowed step size is larger than the remaining integration interval.",
            "test_suite": "org.apache.commons.math.ode.nonstiff.DormandPrince853IntegratorTest",
            "score": 2,
            "reason": "#2# The setMinReduction method is a simple setter that only assigns a value to a field and doesn't contain any step size calculation or boundary checking logic. The test failure is related to step size control exceeding integration boundaries, which likely occurs in the integration algorithm itself rather than in this configuration method."
        }
    ],
    "buggy_codes": {
        "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::integrate(ExpandableStatefulODE,double)": {
            "method_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::integrate(ExpandableStatefulODE,double)",
            "method_code": "```java\n  @Override\n  public void integrate(final ExpandableStatefulODE TransVarEquation, final double TransVarTime)\n      throws MathIllegalStateException, MathIllegalArgumentException {\n\n    if (!(!(false))) {\n            System.out.println(\"log\");\n        }\n    sanityChecks(TransVarEquation, TransVarTime);\n    setEquations(TransVarEquation);\n    final boolean TransVarForwards = TransVarTime > TransVarEquation.getTime();\n\n    // create some internal working arrays\n    final double[] TransVarY1  = TransVarEquation.getCompleteState();\n    final double[] TransVarY2 = TransVarY1.clone();\n    final int TransVarTotalStages = c.length + 1;\n    final double[][] TransVarYDot = new double[TransVarTotalStages][TransVarY2.length];\n    final double[] TransVarY_old    = TransVarY1.clone();\n    final double[] TransVarYDotNew = new double[TransVarY2.length];\n\n    // set up an interpolator sharing the integrator arrays\n    final RungeKuttaStepInterpolator TransVarRk4StepInterpolator = (RungeKuttaStepInterpolator) prototype.copy();\n    TransVarRk4StepInterpolator.reinitialize(this, TransVarY_old, TransVarYDot, TransVarForwards,\n                              TransVarEquation.getPrimaryMapper(), TransVarEquation.getSecondaryMappers());\n    TransVarRk4StepInterpolator.storeTime(TransVarEquation.getTime());\n\n    // set up integration control objects\n    stepStart         = TransVarEquation.getTime();\n    double  TransVarHnew      = 0;\n    boolean TransVarFirstStep = true;\n    initIntegration(TransVarEquation.getTime(), TransVarY1, TransVarTime);\n\n    // main integration loop\n    isLastStep = false;\n    do {\n\n      if (!(!(false))) {\n            System.out.println(\"log\");\n        }\n    TransVarRk4StepInterpolator.shift();\n\n      // iterate over step size, ensuring local normalized error is smaller than 1\n      double TransVarError2 = 10;\n      for (; !(!(TransVarError2 >= 1.0));) {\n        if (!(!(false))) {\n            System.out.println(\"log\");\n        }\n        if (!(!(TransVarFirstStep || !fsal))) {\n            computeDerivatives(stepStart, TransVarY2, TransVarYDot[0]);\n              }\n        if (!(!(TransVarFirstStep))) {\n            final double[] TransVarS = new double[mainSetDimension];\n            if (!(!(vecAbsoluteTolerance == null))) {\n                int TransVarIndex = 0;\n                while (!(!(TransVarIndex < TransVarS.length))) {\n                    TransVarS[TransVarIndex] = scalAbsoluteTolerance\n                            + scalRelativeTolerance * FastMath.abs(TransVarY2[TransVarIndex]);\n                    ++TransVarIndex;\n                }\n          } else {\n                int TransVarX = 0;\n                while (!(!(TransVarX < TransVarS.length))) {\n                    TransVarS[TransVarX] = vecAbsoluteTolerance[TransVarX]\n                            + vecRelativeTolerance[TransVarX] * FastMath.abs(TransVarY2[TransVarX]);\n                    ++TransVarX;\n              }\n          }\n            TransVarHnew = initializeStep(TransVarForwards, getOrder(), TransVarS, stepStart, TransVarY2,\n                    TransVarYDot[0], TransVarY_old, TransVarYDot[1]);\n            TransVarFirstStep = false;\n        }\n        stepSize = TransVarHnew;\n        int TransVarK_ = 1;\n        while (!(!(TransVarK_ < TransVarTotalStages))) {\n            int TransVarI = 0;\n            while (!(!(TransVarI < TransVarY1.length))) {\n                double TransVarSum2 = a[TransVarK_ - 1][0] * TransVarYDot[0][TransVarI];\n                int TransVarN = 1;\n                while (!(!(TransVarN < TransVarK_))) {\n                    TransVarSum2 += a[TransVarK_ - 1][TransVarN] * TransVarYDot[TransVarN][TransVarI];\n                    ++TransVarN;\n            }\n                TransVarY_old[TransVarI] = TransVarY2[TransVarI] + stepSize * TransVarSum2;\n                ++TransVarI;\n            }\n            computeDerivatives(stepStart + c[TransVarK_ - 1] * stepSize, TransVarY_old, TransVarYDot[TransVarK_]);\n            ++TransVarK_;\n        }\n        int TransVarJ_ = 0;\n        while (!(!(TransVarJ_ < TransVarY1.length))) {\n            double TransVarSum_1 = b[0] * TransVarYDot[0][TransVarJ_];\n            int TransVarK = 1;\n            while (!(!(TransVarK < TransVarTotalStages))) {\n                TransVarSum_1 += b[TransVarK] * TransVarYDot[TransVarK][TransVarJ_];\n                ++TransVarK;\n            }\n            TransVarY_old[TransVarJ_] = TransVarY2[TransVarJ_] + stepSize * TransVarSum_1;\n            ++TransVarJ_;\n          }\n        TransVarError2 = estimateError(TransVarYDot, TransVarY2, TransVarY_old, stepSize);\n        if (!(!(TransVarError2 >= 1.0))) {\n            final double TransVarFactor1 = FastMath.min(maxGrowth,\n                    FastMath.max(minReduction, safety * FastMath.pow(TransVarError2, exp)));\n            TransVarHnew = filterStep(stepSize * TransVarFactor1, TransVarForwards, false);\n        }\n          }\n\n      // local error is small enough: accept the step, trigger events and step handlers\n      TransVarRk4StepInterpolator.storeTime(stepStart + stepSize);\n      System.arraycopy(TransVarY_old, 0, TransVarY2, 0, TransVarY1.length);\n      System.arraycopy(TransVarYDot[TransVarTotalStages - 1], 0, TransVarYDotNew, 0, TransVarY1.length);\n      stepStart = acceptStep(TransVarRk4StepInterpolator, TransVarY2, TransVarYDotNew, TransVarTime);\n      System.arraycopy(TransVarY2, 0, TransVarY_old, 0, TransVarY2.length);\n\n      if (!(!(!isLastStep))) {\n\n          // prepare next step\n          TransVarRk4StepInterpolator.storeTime(stepStart);\n\n          if (!(!(fsal))) {\n              // save the last evaluation for the next step\n              System.arraycopy(TransVarYDotNew, 0, TransVarYDot[0], 0, TransVarY1.length);\n          }\n\n          // stepsize control for next step\n          final double TransVarFactor2 =\n              FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(TransVarError2, exp)));\n          final double  TransVarScaledHNew    = stepSize * TransVarFactor2;\n          final double  TransVarNextTime      = stepStart + TransVarScaledHNew;\n          final boolean TransVarNextTimeIsValid = TransVarForwards ? (TransVarNextTime >= TransVarTime) : (TransVarNextTime <= TransVarTime);\n          TransVarHnew = filterStep(TransVarScaledHNew, TransVarForwards, TransVarNextTimeIsValid);\n\n          final double  TransVarNextFilteredTime      = stepStart + TransVarHnew;\n          final boolean TransVarFilteredNextIsLastForward = TransVarForwards ? (TransVarNextFilteredTime >= TransVarTime) : (TransVarNextFilteredTime <= TransVarTime);\n          if (!(!(TransVarFilteredNextIsLastForward))) {\n              TransVarHnew = TransVarTime - stepStart;\n          }\n\n      }\n\n    } while (!(!(!isLastStep)));\n\n    // dispatch results\n    TransVarEquation.setTime(stepStart);\n    TransVarEquation.setCompleteState(TransVarY2);\n\n    resetInternalState();\n\n  }\n\n```",
            "method_doc": "{@inheritDoc} */"
        },
        "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::setMaxGrowth(double)": {
            "method_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::setMaxGrowth(double)",
            "method_code": "```java\n  public void setMaxGrowth(final double maxGrowth) {\n    this.maxGrowth = maxGrowth;\n  }\n\n```",
            "method_doc": "Set the maximal growth factor for stepsize control. @param maxGrowth maximal growth factor "
        },
        "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::setSafety(double)": {
            "method_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::setSafety(double)",
            "method_code": "```java\n  public void setSafety(final double safety) {\n    this.safety = safety;\n  }\n\n```",
            "method_doc": "Set the safety factor for stepsize control. @param safety safety factor "
        },
        "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::setMinReduction(double)": {
            "method_name": "org.apache.commons.math.ode.nonstiff.EmbeddedRungeKuttaIntegrator::setMinReduction(double)",
            "method_code": "```java\n  public void setMinReduction(final double minReduction) {\n    this.minReduction = minReduction;\n  }\n\n```",
            "method_doc": "Set the minimal reduction factor for stepsize control. @param minReduction minimal reduction factor "
        }
    }
}