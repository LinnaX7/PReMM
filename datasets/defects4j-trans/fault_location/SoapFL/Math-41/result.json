{
    "buggy_classes": [
        "org.apache.commons.math.stat.descriptive.moment.Variance"
    ],
    "buggy_methods": [
        {
            "method_name": "org.apache.commons.math.stat.descriptive.moment.Variance::evaluate(double[],double[],double,int,int)",
            "method_code": "```java\n    public double evaluate(final double[] TransVarData, final double[] TransVarWeight,\n                           final double TransVarAverage, final int TransVarInitial, final int TransVarDataLength) {\n\n        if (!(!(false))) {\n                                System.out.println(\"log\");\n                            }\n        double TransVarDataValue = Double.NaN;\n\n        if (!(!(test(TransVarData, TransVarWeight, TransVarInitial, TransVarDataLength)))) {\n            if (!(!(false))) {\n                System.out.println(\"log\");\n                }\n            if (!(!(TransVarDataLength == 1))) {\n                if (!(!(false))) {\n                    System.out.println(\"log\");\n                }\n                TransVarDataValue = 0.0;\n            } else if (!(!(TransVarDataLength > 1))) {\n                double TransVarSum = 0.0;\n                double TransVarDeviation = 0.0;\n                double TransVarAccum = 0.0;\n                int TransVarIndex = TransVarInitial;\n                while (!(!(TransVarIndex < TransVarInitial + TransVarDataLength))) {\n                    TransVarDeviation = TransVarData[TransVarIndex] - TransVarAverage;\n                    TransVarSum += TransVarWeight[TransVarIndex] * (TransVarDeviation * TransVarDeviation);\n                    TransVarAccum += TransVarWeight[TransVarIndex] * TransVarDeviation;\n                    TransVarIndex++;\n                }\n\n                double TransVarSumOfWts = 0;\n                int TransVarN = 0;\n                while (!(!(TransVarN < TransVarWeight.length))) {\n                    TransVarSumOfWts += TransVarWeight[TransVarN];\n                    TransVarN++;\n                }\n\n                if (!(!(isBiasCorrected))) {\n                    TransVarDataValue = (TransVarSum - (TransVarAccum * TransVarAccum / TransVarSumOfWts)) / (TransVarSumOfWts - 1.0);\n                } else {\n                    TransVarDataValue = (TransVarSum - (TransVarAccum * TransVarAccum / TransVarSumOfWts)) / TransVarSumOfWts;\n                }\n            }\n        }\n        return TransVarDataValue;\n    }\n\n```",
            "method_doc": " Returns the weighted variance of the entries in the specified portion of the input array, using the precomputed weighted mean value.  Returns <code>Double.NaN</code> if the designated subarray is empty. <p> Uses the formula <pre> &Sigma;(weights[i]*(values[i] - mean)<sup>2</sup>)/(&Sigma;(weights[i]) - 1) </pre></p> <p> The formula used assumes that the supplied mean value is the weighted arithmetic mean of the sample data, not a known population parameter. This method is supplied only to save computation when the mean has already been computed.</p> <p> This formula will not return the same result as the unweighted variance when all weights are equal, unless all weights are equal to 1. The formula assumes that weights are to be treated as \"expansion values,\" as will be the case if for example the weights represent frequency counts. To normalize weights so that the denominator in the variance computation equals the length of the input vector minus one, use <pre> <code>evaluate(values, MathArrays.normalizeArray(weights, values.length), mean); </code> </pre> <p> Returns 0 for a single-value (i.e. length = 1) sample.</p> <p> Throws <code>IllegalArgumentException</code> if any of the following are true: <ul><li>the values array is null</li> <li>the weights array is null</li> <li>the weights array does not have the same length as the values array</li> <li>the weights array contains one or more infinite values</li> <li>the weights array contains one or more NaN values</li> <li>the weights array contains negative values</li> <li>the start and length arguments do not determine a valid array</li> </ul></p> <p> Does not change the internal state of the statistic.</p>  @param values the input array @param weights the weights array @param mean the precomputed weighted mean value @param begin index of the first array element to include @param length the number of elements to include @return the variance of the values or Double.NaN if length = 0 @throws IllegalArgumentException if the parameters are not valid @since 2.1 ",
            "class_name": "org.apache.commons.math.stat.descriptive.moment.Variance",
            "class_doc": " Computes the variance of the available values.  By default, the unbiased \"sample variance\" definitional formula is used: <p> variance = sum((x_i - mean)^2) / (n - 1) </p> <p> where mean is the {@link Mean} and <code>n</code> is the number of sample observations.</p> <p> The definitional formula does not have good numerical properties, so this implementation does not compute the statistic using the definitional formula. <ul> <li> The <code>getResult</code> method computes the variance using updating formulas based on West's algorithm, as described in <a href=\"http://doi.acm.org/10.1145/359146.359152\"> Chan, T. F. and J. G. Lewis 1979, <i>Communications of the ACM</i>, vol. 22 no. 9, pp. 526-531.</a></li> <li> The <code>evaluate</code> methods leverage the fact that they have the full array of values in memory to execute a two-pass algorithm. Specifically, these methods use the \"corrected two-pass algorithm\" from Chan, Golub, Levesque, <i>Algorithms for Computing the Sample Variance</i>, American Statistician, vol. 37, no. 3 (1983) pp. 242-247.</li></ul> Note that adding values using <code>increment</code> or <code>incrementAll</code> and then executing <code>getResult</code> will sometimes give a different, less accurate, result than executing <code>evaluate</code> with the full array of values. The former approach should only be used when the full array of values is not available.</p> <p> The \"population variance\"  ( sum((x_i - mean)^2) / n ) can also be computed using this statistic.  The <code>isBiasCorrected</code> property determines whether the \"population\" or \"sample\" value is returned by the <code>evaluate</code> and <code>getResult</code> methods. To compute population variances, set this property to <code>false.</code> </p> <p> <strong>Note that this implementation is not synchronized.</strong> If multiple threads access an instance of this class concurrently, and at least one of the threads invokes the <code>increment()</code> or <code>clear()</code> method, it must be synchronized externally.</p>  @version $Id$ ",
            "test_failure_causes": "Based on my analysis of the failed test behavior and stack trace, here's my step-by-step reasoning:\n\n## Pattern Analysis\n\n1. **Common Failure Pattern**: The test `testEvaluateArraySegmentWeighted` fails at the first assertion comparing weighted variance calculations between:\n   - A copied subarray with its weights: `stat.evaluate(arrayZero, weightZero)`\n   - A segment of the original arrays: `stat.evaluate(testArray, testWeightsArray, 0, 5)`\n\n2. **Numerical Discrepancy**: The expected value (1.6644508338125354) differs significantly from the actual value (0.31909161062727365), indicating a substantial calculation error.\n\n3. **Specific Failure Context**: The failure occurs only in weighted variance calculations with array segments, suggesting the issue relates to how weights are handled when processing array segments.\n\n## Recommended Production Code Defect\n\nThe likely defect is in the `Variance.evaluate(double[] values, double[] weights, int start, int length)` method implementation. Specifically:\n\n**The weight array indexing is not properly synchronized with the value array when processing segments.** \n\nWhen the method processes a segment of the values array (from `start` to `start+length`), it should apply the corresponding segment of the weights array (same `start` and `length` parameters). The failure suggests that either:\n\n1. The weights are being applied from index 0 instead of the specified `start` index, or\n2. The weight normalization or calculation logic incorrectly handles segmented arrays\n3. There's an off-by-one error in how weights are indexed during segment processing\n\nThis would explain why calculating variance on a copied subarray (where weights are properly aligned) produces different results than using segment parameters on the original arrays (where weight indexing may be misaligned).",
            "test_suite": "org.apache.commons.math.stat.descriptive.moment.VarianceTest",
            "score": 10,
            "reason": "#10# This method is highly suspicious because it contains a critical bug in the weight array processing. The second while loop incorrectly calculates TransVarSumOfWts by iterating over the entire TransVarWeight array (from index 0 to TransVarWeight.length-1) instead of only the segment specified by TransVarInitial and TransVarDataLength. This causes incorrect weight normalization when processing array segments, explaining why the weighted variance calculation differs between copied subarrays and segment-based evaluations."
        },
        {
            "method_name": "org.apache.commons.math.stat.descriptive.moment.Variance::evaluate(double[],double[],int,int)",
            "method_code": "```java\n    public double evaluate(final double[] values, final double[] weights,\n                           final int begin, final int length) {\n\n        double var = Double.NaN;\n\n        if (test(values, weights,begin, length)) {\n            clear();\n            if (length == 1) {\n                var = 0.0;\n            } else if (length > 1) {\n                Mean mean = new Mean();\n                double m = mean.evaluate(values, weights, begin, length);\n                var = evaluate(values, weights, m, begin, length);\n            }\n        }\n        return var;\n    }\n\n```",
            "method_doc": " <p>Returns the weighted variance of the entries in the specified portion of the input array, or <code>Double.NaN</code> if the designated subarray is empty.</p> <p> Uses the formula <pre> &Sigma;(weights[i]*(values[i] - weightedMean)<sup>2</sup>)/(&Sigma;(weights[i]) - 1) </pre> where weightedMean is the weighted mean</p> <p> This formula will not return the same result as the unweighted variance when all weights are equal, unless all weights are equal to 1. The formula assumes that weights are to be treated as \"expansion values,\" as will be the case if for example the weights represent frequency counts. To normalize weights so that the denominator in the variance computation equals the length of the input vector minus one, use <pre> <code>evaluate(values, MathArrays.normalizeArray(weights, values.length)); </code> </pre> <p> Returns 0 for a single-value (i.e. length = 1) sample.</p> <p> Throws <code>IllegalArgumentException</code> if any of the following are true: <ul><li>the values array is null</li> <li>the weights array is null</li> <li>the weights array does not have the same length as the values array</li> <li>the weights array contains one or more infinite values</li> <li>the weights array contains one or more NaN values</li> <li>the weights array contains negative values</li> <li>the start and length arguments do not determine a valid array</li> </ul></p> <p> Does not change the internal state of the statistic.</p> <p> Throws <code>IllegalArgumentException</code> if either array is null.</p>  @param values the input array @param weights the weights array @param begin index of the first array element to include @param length the number of elements to include @return the weighted variance of the values or Double.NaN if length = 0 @throws IllegalArgumentException if the parameters are not valid @since 2.1 ",
            "class_name": "org.apache.commons.math.stat.descriptive.moment.Variance",
            "class_doc": " Computes the variance of the available values.  By default, the unbiased \"sample variance\" definitional formula is used: <p> variance = sum((x_i - mean)^2) / (n - 1) </p> <p> where mean is the {@link Mean} and <code>n</code> is the number of sample observations.</p> <p> The definitional formula does not have good numerical properties, so this implementation does not compute the statistic using the definitional formula. <ul> <li> The <code>getResult</code> method computes the variance using updating formulas based on West's algorithm, as described in <a href=\"http://doi.acm.org/10.1145/359146.359152\"> Chan, T. F. and J. G. Lewis 1979, <i>Communications of the ACM</i>, vol. 22 no. 9, pp. 526-531.</a></li> <li> The <code>evaluate</code> methods leverage the fact that they have the full array of values in memory to execute a two-pass algorithm. Specifically, these methods use the \"corrected two-pass algorithm\" from Chan, Golub, Levesque, <i>Algorithms for Computing the Sample Variance</i>, American Statistician, vol. 37, no. 3 (1983) pp. 242-247.</li></ul> Note that adding values using <code>increment</code> or <code>incrementAll</code> and then executing <code>getResult</code> will sometimes give a different, less accurate, result than executing <code>evaluate</code> with the full array of values. The former approach should only be used when the full array of values is not available.</p> <p> The \"population variance\"  ( sum((x_i - mean)^2) / n ) can also be computed using this statistic.  The <code>isBiasCorrected</code> property determines whether the \"population\" or \"sample\" value is returned by the <code>evaluate</code> and <code>getResult</code> methods. To compute population variances, set this property to <code>false.</code> </p> <p> <strong>Note that this implementation is not synchronized.</strong> If multiple threads access an instance of this class concurrently, and at least one of the threads invokes the <code>increment()</code> or <code>clear()</code> method, it must be synchronized externally.</p>  @version $Id$ ",
            "test_failure_causes": "Based on my analysis of the failed test behavior and stack trace, here's my step-by-step reasoning:\n\n## Pattern Analysis\n\n1. **Common Failure Pattern**: The test `testEvaluateArraySegmentWeighted` fails at the first assertion comparing weighted variance calculations between:\n   - A copied subarray with its weights: `stat.evaluate(arrayZero, weightZero)`\n   - A segment of the original arrays: `stat.evaluate(testArray, testWeightsArray, 0, 5)`\n\n2. **Numerical Discrepancy**: The expected value (1.6644508338125354) differs significantly from the actual value (0.31909161062727365), indicating a substantial calculation error.\n\n3. **Specific Failure Context**: The failure occurs only in weighted variance calculations with array segments, suggesting the issue relates to how weights are handled when processing array segments.\n\n## Recommended Production Code Defect\n\nThe likely defect is in the `Variance.evaluate(double[] values, double[] weights, int start, int length)` method implementation. Specifically:\n\n**The weight array indexing is not properly synchronized with the value array when processing segments.** \n\nWhen the method processes a segment of the values array (from `start` to `start+length`), it should apply the corresponding segment of the weights array (same `start` and `length` parameters). The failure suggests that either:\n\n1. The weights are being applied from index 0 instead of the specified `start` index, or\n2. The weight normalization or calculation logic incorrectly handles segmented arrays\n3. There's an off-by-one error in how weights are indexed during segment processing\n\nThis would explain why calculating variance on a copied subarray (where weights are properly aligned) produces different results than using segment parameters on the original arrays (where weight indexing may be misaligned).",
            "test_suite": "org.apache.commons.math.stat.descriptive.moment.VarianceTest",
            "score": 9,
            "reason": "#9# This method is highly suspicious because it directly handles weighted variance calculations with array segments, which matches the exact failure pattern in the test. The test compares results between copied subarrays and array segments, and the significant numerical discrepancy (1.66 vs 0.32) suggests the weight indexing or calculation logic is incorrect when processing segments. The method's implementation shows it delegates to another evaluate method after computing the mean, but the issue likely occurs in how weights are applied to the specific segment range defined by begin and length parameters."
        },
        {
            "method_name": "org.apache.commons.math.stat.descriptive.moment.Variance::evaluate(double[],double[])",
            "method_code": "```java\n    public double evaluate(final double[] values, final double[] weights) {\n        return evaluate(values, weights, 0, values.length);\n    }\n\n```",
            "method_doc": " <p> Returns the weighted variance of the entries in the the input array.</p> <p> Uses the formula <pre> &Sigma;(weights[i]*(values[i] - weightedMean)<sup>2</sup>)/(&Sigma;(weights[i]) - 1) </pre> where weightedMean is the weighted mean</p> <p> This formula will not return the same result as the unweighted variance when all weights are equal, unless all weights are equal to 1. The formula assumes that weights are to be treated as \"expansion values,\" as will be the case if for example the weights represent frequency counts. To normalize weights so that the denominator in the variance computation equals the length of the input vector minus one, use <pre> <code>evaluate(values, MathArrays.normalizeArray(weights, values.length)); </code> </pre> <p> Returns 0 for a single-value (i.e. length = 1) sample.</p> <p> Throws <code>IllegalArgumentException</code> if any of the following are true: <ul><li>the values array is null</li> <li>the weights array is null</li> <li>the weights array does not have the same length as the values array</li> <li>the weights array contains one or more infinite values</li> <li>the weights array contains one or more NaN values</li> <li>the weights array contains negative values</li> </ul></p> <p> Does not change the internal state of the statistic.</p> <p> Throws <code>IllegalArgumentException</code> if either array is null.</p>  @param values the input array @param weights the weights array @return the weighted variance of the values @throws IllegalArgumentException if the parameters are not valid @since 2.1 ",
            "class_name": "org.apache.commons.math.stat.descriptive.moment.Variance",
            "class_doc": " Computes the variance of the available values.  By default, the unbiased \"sample variance\" definitional formula is used: <p> variance = sum((x_i - mean)^2) / (n - 1) </p> <p> where mean is the {@link Mean} and <code>n</code> is the number of sample observations.</p> <p> The definitional formula does not have good numerical properties, so this implementation does not compute the statistic using the definitional formula. <ul> <li> The <code>getResult</code> method computes the variance using updating formulas based on West's algorithm, as described in <a href=\"http://doi.acm.org/10.1145/359146.359152\"> Chan, T. F. and J. G. Lewis 1979, <i>Communications of the ACM</i>, vol. 22 no. 9, pp. 526-531.</a></li> <li> The <code>evaluate</code> methods leverage the fact that they have the full array of values in memory to execute a two-pass algorithm. Specifically, these methods use the \"corrected two-pass algorithm\" from Chan, Golub, Levesque, <i>Algorithms for Computing the Sample Variance</i>, American Statistician, vol. 37, no. 3 (1983) pp. 242-247.</li></ul> Note that adding values using <code>increment</code> or <code>incrementAll</code> and then executing <code>getResult</code> will sometimes give a different, less accurate, result than executing <code>evaluate</code> with the full array of values. The former approach should only be used when the full array of values is not available.</p> <p> The \"population variance\"  ( sum((x_i - mean)^2) / n ) can also be computed using this statistic.  The <code>isBiasCorrected</code> property determines whether the \"population\" or \"sample\" value is returned by the <code>evaluate</code> and <code>getResult</code> methods. To compute population variances, set this property to <code>false.</code> </p> <p> <strong>Note that this implementation is not synchronized.</strong> If multiple threads access an instance of this class concurrently, and at least one of the threads invokes the <code>increment()</code> or <code>clear()</code> method, it must be synchronized externally.</p>  @version $Id$ ",
            "test_failure_causes": "Based on my analysis of the failed test behavior and stack trace, here's my step-by-step reasoning:\n\n## Pattern Analysis\n\n1. **Common Failure Pattern**: The test `testEvaluateArraySegmentWeighted` fails at the first assertion comparing weighted variance calculations between:\n   - A copied subarray with its weights: `stat.evaluate(arrayZero, weightZero)`\n   - A segment of the original arrays: `stat.evaluate(testArray, testWeightsArray, 0, 5)`\n\n2. **Numerical Discrepancy**: The expected value (1.6644508338125354) differs significantly from the actual value (0.31909161062727365), indicating a substantial calculation error.\n\n3. **Specific Failure Context**: The failure occurs only in weighted variance calculations with array segments, suggesting the issue relates to how weights are handled when processing array segments.\n\n## Recommended Production Code Defect\n\nThe likely defect is in the `Variance.evaluate(double[] values, double[] weights, int start, int length)` method implementation. Specifically:\n\n**The weight array indexing is not properly synchronized with the value array when processing segments.** \n\nWhen the method processes a segment of the values array (from `start` to `start+length`), it should apply the corresponding segment of the weights array (same `start` and `length` parameters). The failure suggests that either:\n\n1. The weights are being applied from index 0 instead of the specified `start` index, or\n2. The weight normalization or calculation logic incorrectly handles segmented arrays\n3. There's an off-by-one error in how weights are indexed during segment processing\n\nThis would explain why calculating variance on a copied subarray (where weights are properly aligned) produces different results than using segment parameters on the original arrays (where weight indexing may be misaligned).",
            "test_suite": "org.apache.commons.math.stat.descriptive.moment.VarianceTest",
            "score": 8,
            "reason": "#8# This method is very likely to be the best location that needs to be fixed because it directly calls the overloaded evaluate method with segment parameters (0, values.length), and the test failure specifically occurs when comparing results between full array evaluation and segmented array evaluation with weights. The issue appears to be in how weights are handled during segment processing, and since this method serves as the entry point for weighted variance calculations, any fix should start here or in the method it delegates to."
        }
    ],
    "buggy_codes": {
        "org.apache.commons.math.stat.descriptive.moment.Variance::evaluate(double[],double[],int,int)": {
            "method_name": "org.apache.commons.math.stat.descriptive.moment.Variance::evaluate(double[],double[],int,int)",
            "method_code": "```java\n    public double evaluate(final double[] values, final double[] weights,\n                           final int begin, final int length) {\n\n        double var = Double.NaN;\n\n        if (test(values, weights,begin, length)) {\n            clear();\n            if (length == 1) {\n                var = 0.0;\n            } else if (length > 1) {\n                Mean mean = new Mean();\n                double m = mean.evaluate(values, weights, begin, length);\n                var = evaluate(values, weights, m, begin, length);\n            }\n        }\n        return var;\n    }\n\n```",
            "method_doc": " <p>Returns the weighted variance of the entries in the specified portion of the input array, or <code>Double.NaN</code> if the designated subarray is empty.</p> <p> Uses the formula <pre> &Sigma;(weights[i]*(values[i] - weightedMean)<sup>2</sup>)/(&Sigma;(weights[i]) - 1) </pre> where weightedMean is the weighted mean</p> <p> This formula will not return the same result as the unweighted variance when all weights are equal, unless all weights are equal to 1. The formula assumes that weights are to be treated as \"expansion values,\" as will be the case if for example the weights represent frequency counts. To normalize weights so that the denominator in the variance computation equals the length of the input vector minus one, use <pre> <code>evaluate(values, MathArrays.normalizeArray(weights, values.length)); </code> </pre> <p> Returns 0 for a single-value (i.e. length = 1) sample.</p> <p> Throws <code>IllegalArgumentException</code> if any of the following are true: <ul><li>the values array is null</li> <li>the weights array is null</li> <li>the weights array does not have the same length as the values array</li> <li>the weights array contains one or more infinite values</li> <li>the weights array contains one or more NaN values</li> <li>the weights array contains negative values</li> <li>the start and length arguments do not determine a valid array</li> </ul></p> <p> Does not change the internal state of the statistic.</p> <p> Throws <code>IllegalArgumentException</code> if either array is null.</p>  @param values the input array @param weights the weights array @param begin index of the first array element to include @param length the number of elements to include @return the weighted variance of the values or Double.NaN if length = 0 @throws IllegalArgumentException if the parameters are not valid @since 2.1 "
        },
        "org.apache.commons.math.stat.descriptive.moment.Variance::evaluate(double[],double[])": {
            "method_name": "org.apache.commons.math.stat.descriptive.moment.Variance::evaluate(double[],double[])",
            "method_code": "```java\n    public double evaluate(final double[] values, final double[] weights) {\n        return evaluate(values, weights, 0, values.length);\n    }\n\n```",
            "method_doc": " <p> Returns the weighted variance of the entries in the the input array.</p> <p> Uses the formula <pre> &Sigma;(weights[i]*(values[i] - weightedMean)<sup>2</sup>)/(&Sigma;(weights[i]) - 1) </pre> where weightedMean is the weighted mean</p> <p> This formula will not return the same result as the unweighted variance when all weights are equal, unless all weights are equal to 1. The formula assumes that weights are to be treated as \"expansion values,\" as will be the case if for example the weights represent frequency counts. To normalize weights so that the denominator in the variance computation equals the length of the input vector minus one, use <pre> <code>evaluate(values, MathArrays.normalizeArray(weights, values.length)); </code> </pre> <p> Returns 0 for a single-value (i.e. length = 1) sample.</p> <p> Throws <code>IllegalArgumentException</code> if any of the following are true: <ul><li>the values array is null</li> <li>the weights array is null</li> <li>the weights array does not have the same length as the values array</li> <li>the weights array contains one or more infinite values</li> <li>the weights array contains one or more NaN values</li> <li>the weights array contains negative values</li> </ul></p> <p> Does not change the internal state of the statistic.</p> <p> Throws <code>IllegalArgumentException</code> if either array is null.</p>  @param values the input array @param weights the weights array @return the weighted variance of the values @throws IllegalArgumentException if the parameters are not valid @since 2.1 "
        },
        "org.apache.commons.math.stat.descriptive.moment.Variance::evaluate(double[],double[],double,int,int)": {
            "method_name": "org.apache.commons.math.stat.descriptive.moment.Variance::evaluate(double[],double[],double,int,int)",
            "method_code": "```java\n    public double evaluate(final double[] TransVarData, final double[] TransVarWeight,\n                           final double TransVarAverage, final int TransVarInitial, final int TransVarDataLength) {\n\n        if (!(!(false))) {\n                                System.out.println(\"log\");\n                            }\n        double TransVarDataValue = Double.NaN;\n\n        if (!(!(test(TransVarData, TransVarWeight, TransVarInitial, TransVarDataLength)))) {\n            if (!(!(false))) {\n                System.out.println(\"log\");\n                }\n            if (!(!(TransVarDataLength == 1))) {\n                if (!(!(false))) {\n                    System.out.println(\"log\");\n                }\n                TransVarDataValue = 0.0;\n            } else if (!(!(TransVarDataLength > 1))) {\n                double TransVarSum = 0.0;\n                double TransVarDeviation = 0.0;\n                double TransVarAccum = 0.0;\n                int TransVarIndex = TransVarInitial;\n                while (!(!(TransVarIndex < TransVarInitial + TransVarDataLength))) {\n                    TransVarDeviation = TransVarData[TransVarIndex] - TransVarAverage;\n                    TransVarSum += TransVarWeight[TransVarIndex] * (TransVarDeviation * TransVarDeviation);\n                    TransVarAccum += TransVarWeight[TransVarIndex] * TransVarDeviation;\n                    TransVarIndex++;\n                }\n\n                double TransVarSumOfWts = 0;\n                int TransVarN = 0;\n                while (!(!(TransVarN < TransVarWeight.length))) {\n                    TransVarSumOfWts += TransVarWeight[TransVarN];\n                    TransVarN++;\n                }\n\n                if (!(!(isBiasCorrected))) {\n                    TransVarDataValue = (TransVarSum - (TransVarAccum * TransVarAccum / TransVarSumOfWts)) / (TransVarSumOfWts - 1.0);\n                } else {\n                    TransVarDataValue = (TransVarSum - (TransVarAccum * TransVarAccum / TransVarSumOfWts)) / TransVarSumOfWts;\n                }\n            }\n        }\n        return TransVarDataValue;\n    }\n\n```",
            "method_doc": " Returns the weighted variance of the entries in the specified portion of the input array, using the precomputed weighted mean value.  Returns <code>Double.NaN</code> if the designated subarray is empty. <p> Uses the formula <pre> &Sigma;(weights[i]*(values[i] - mean)<sup>2</sup>)/(&Sigma;(weights[i]) - 1) </pre></p> <p> The formula used assumes that the supplied mean value is the weighted arithmetic mean of the sample data, not a known population parameter. This method is supplied only to save computation when the mean has already been computed.</p> <p> This formula will not return the same result as the unweighted variance when all weights are equal, unless all weights are equal to 1. The formula assumes that weights are to be treated as \"expansion values,\" as will be the case if for example the weights represent frequency counts. To normalize weights so that the denominator in the variance computation equals the length of the input vector minus one, use <pre> <code>evaluate(values, MathArrays.normalizeArray(weights, values.length), mean); </code> </pre> <p> Returns 0 for a single-value (i.e. length = 1) sample.</p> <p> Throws <code>IllegalArgumentException</code> if any of the following are true: <ul><li>the values array is null</li> <li>the weights array is null</li> <li>the weights array does not have the same length as the values array</li> <li>the weights array contains one or more infinite values</li> <li>the weights array contains one or more NaN values</li> <li>the weights array contains negative values</li> <li>the start and length arguments do not determine a valid array</li> </ul></p> <p> Does not change the internal state of the statistic.</p>  @param values the input array @param weights the weights array @param mean the precomputed weighted mean value @param begin index of the first array element to include @param length the number of elements to include @return the variance of the values or Double.NaN if length = 0 @throws IllegalArgumentException if the parameters are not valid @since 2.1 "
        }
    }
}